{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E6CB9uB9J-Sr"
      },
      "outputs": [],
      "source": [
        "# Define a function that sets custom CSS for the notebook output\n",
        "# This specific style makes <pre> blocks wrap text instead of overflowing in a single line\n",
        "def set_css():\n",
        "    display(HTML('''\n",
        "    <style>\n",
        "      pre {\n",
        "          white-space: pre-wrap;  /* Enable word-wrapping in code/output blocks */\n",
        "      }\n",
        "    </style>\n",
        "    '''))\n",
        "\n",
        "# Register the CSS-setting function to run automatically before each code cell runs\n",
        "# This ensures the styling stays applied throughout the notebook session\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3-Z1KKCCtSe"
      },
      "source": [
        "# Large Language Model Embeddings and Retrieval-Augmented Generation\n",
        "\n",
        "This module focuses on creating a complete Retrieval-Augmented Generation (RAG) system using modern NLP techniques, embedding models, and vector databases. The system allows users to search through text documents semantically and receive AI-generated answers based on relevant retrieved contexts.\n",
        "\n",
        "## Objective\n",
        "The main objective of this module is to demonstrate how to:\n",
        "1. Process and chunk text documents for efficient retrieval\n",
        "2. Generate high-quality embeddings using pre-trained models\n",
        "3. Store and query vector embeddings in a vector database (Qdrant)\n",
        "4. Implement a complete RAG pipeline by connecting retrieval with an LLM\n",
        "5. Create a user-friendly interface for interacting with the RAG system\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "IjCDszI_KX0G",
        "outputId": "9d8176f7-cec4-4501-9ff2-623ef790b03b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x106650b80> (for pre_run_cell), with arguments args (<ExecutionInfo object at 1067839b0, raw_cell=\"import markdown\n",
            "from IPython.display import displa..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/kiran.ramanna/Documents/github/2025stanford/005-module/module_5_large_embeddingv1_1_Tech103.ipynb#W2sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[31mTypeError\u001b[39m: set_css() takes 0 positional arguments but 1 was given"
          ]
        }
      ],
      "source": [
        "import markdown\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def render_markdown(md_text):\n",
        "    # Convert Markdown to HTML\n",
        "    html = markdown.markdown(md_text)\n",
        "    # Display the HTML\n",
        "    display(HTML(html))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHhuO8IoDyQA"
      },
      "source": [
        "## Setup and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ1aqJD-CumT",
        "outputId": "35af23d0-3909-43b0-eebd-c0c5b62c3984"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x106650b80> (for pre_run_cell), with arguments args (<ExecutionInfo object at 1067aa690, raw_cell=\"# Install the necessary libraries\n",
            "!pip install sen..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/kiran.ramanna/Documents/github/2025stanford/005-module/module_5_large_embeddingv1_1_Tech103.ipynb#W4sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[31mTypeError\u001b[39m: set_css() takes 0 positional arguments but 1 was given"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: sentence_transformers in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (3.3.1)\n",
            "Requirement already satisfied: openai in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (1.55.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from sentence_transformers) (4.46.3)\n",
            "Requirement already satisfied: tqdm in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from sentence_transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from sentence_transformers) (2.5.1)\n",
            "Requirement already satisfied: scikit-learn in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from sentence_transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from sentence_transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from sentence_transformers) (0.26.2)\n",
            "Requirement already satisfied: Pillow in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from sentence_transformers) (11.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from openai) (4.6.2.post1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from openai) (0.8.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from openai) (2.10.2)\n",
            "Requirement already satisfied: sniffio in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: filelock in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
            "Requirement already satisfied: networkx in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (75.6.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Collecting plotly\n",
            "  Downloading plotly-6.0.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting narwhals>=1.15.1 (from plotly)\n",
            "  Downloading narwhals-1.37.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: packaging in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from plotly) (24.2)\n",
            "Downloading plotly-6.0.1-py3-none-any.whl (14.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading narwhals-1.37.1-py3-none-any.whl (332 kB)\n",
            "Installing collected packages: narwhals, plotly\n",
            "Successfully installed narwhals-1.37.1 plotly-6.0.1\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: matplotlib in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "autoeval-micro-judges 0.1.0 requires rich<14.0.0,>=13.8.1, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Collecting qdrant_client\n",
            "  Downloading qdrant_client-1.14.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from qdrant_client) (1.70.0)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from httpx[http2]>=0.20.0->qdrant_client) (0.27.2)\n",
            "Requirement already satisfied: numpy>=1.26 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from qdrant_client) (1.26.4)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant_client)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from qdrant_client) (5.28.3)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from qdrant_client) (2.10.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from qdrant_client) (2.2.3)\n",
            "Requirement already satisfied: anyio in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (4.6.2.post1)\n",
            "Requirement already satisfied: certifi in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.0.7)\n",
            "Requirement already satisfied: idna in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.10)\n",
            "Requirement already satisfied: sniffio in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (0.14.0)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant_client)\n",
            "  Downloading h2-4.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (4.13.2)\n",
            "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client)\n",
            "  Downloading hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client)\n",
            "  Downloading hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Downloading qdrant_client-1.14.2-py3-none-any.whl (327 kB)\n",
            "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading h2-4.2.0-py3-none-any.whl (60 kB)\n",
            "Downloading hpack-4.1.0-py3-none-any.whl (34 kB)\n",
            "Downloading hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: portalocker, hyperframe, hpack, h2, qdrant_client\n",
            "Successfully installed h2-4.2.0 hpack-4.1.0 hyperframe-6.1.0 portalocker-2.10.1 qdrant_client-1.14.2\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: transformers in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/kiran.ramanna/anaconda3/envs/ais_ml1/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "131072"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Install the necessary libraries\n",
        "!pip install sentence_transformers openai\n",
        "!pip install plotly\n",
        "!pip install matplotlib\n",
        "!pip install -Uqqq rich openai gradio\n",
        "!pip install qdrant_client\n",
        "!pip install transformers\n",
        "\n",
        "# Import basic libraries\n",
        "import numpy as np\n",
        "import os, random\n",
        "from pathlib import Path\n",
        "from getpass import getpass\n",
        "from rich.markdown import Markdown\n",
        "import torch\n",
        "import sys\n",
        "import csv\n",
        "csv.field_size_limit(sys.maxsize)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bXxwyEzDsFh"
      },
      "source": [
        "## OpenAI-Compatible LLM Client Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xNFeSRiVCYxK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x106650b80> (for pre_run_cell), with arguments args (<ExecutionInfo object at 1067aac60, raw_cell=\"# Retrieve API key securely from Colab user data\n",
            "#..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/kiran.ramanna/Documents/github/2025stanford/005-module/module_5_large_embeddingv1_1_Tech103.ipynb#W6sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[31mTypeError\u001b[39m: set_css() takes 0 positional arguments but 1 was given"
          ]
        }
      ],
      "source": [
        "# Retrieve API key securely from Colab user data\n",
        "# from google.colab import userdata\n",
        "# OPEN_ROUTER_API_KEY = userdata.get('OPEN_ROUTER_API_KEY')\n",
        "# OPEN_ROUTER_API_KEY = \"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\"\n",
        "OPEN_ROUTER_API_KEY = os.getenv(\"OPENROUTER_API_KEY\")\n",
        "\n",
        "# Initialize OpenRouter client (OpenAI-compatible API)\n",
        "from openai import OpenAI\n",
        "open_router_client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=OPEN_ROUTER_API_KEY,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHAvXKCiDuQv"
      },
      "source": [
        "## Data Loading and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8iSOZm64Cqvk",
        "outputId": "d8fc4ad2-c5c3-41e4-9ed7-e20658905538"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x106650b80> (for pre_run_cell), with arguments args (<ExecutionInfo object at 166146d80, raw_cell=\"# Load data from Google Drive\n",
            "import pandas as pd\n",
            "..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/kiran.ramanna/Documents/github/2025stanford/005-module/module_5_large_embeddingv1_1_Tech103.ipynb#X11sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[31mTypeError\u001b[39m: set_css() takes 0 positional arguments but 1 was given"
          ]
        }
      ],
      "source": [
        "# Load data from Google Drive\n",
        "import pandas as pd\n",
        "url = 'https://drive.google.com/uc?id=1gl7WAkJr6Nyke7YckzXxdL-iM4UjhLGX'\n",
        "df = pd.read_csv(url)\n",
        "df = df[:5]  # Using only 5 rows for demonstration\n",
        "df = df.dropna(axis=1)  # Drop columns with null values\n",
        "\n",
        "# Prepare data with metadata for traceability\n",
        "data = []\n",
        "for row_num, row in df.iterrows():\n",
        "    content = \" \".join([f\"{col}: {row[col]}\" for col in df.columns])\n",
        "    data.append({\n",
        "        \"page_content\": content,\n",
        "        \"metadata\": {\n",
        "            \"source\": row[\"title\"],\n",
        "        }\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5Wfp4Z5D7Eo"
      },
      "source": [
        "## Document Chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "cnicbr6AD5jq",
        "outputId": "b9ed4db9-7b95-4689-c7ec-ba52d0e3eef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x106650b80> (for pre_run_cell), with arguments args (<ExecutionInfo object at 169986a80, raw_cell=\"def simple_recursive_split(docs, chunk_size=1000, ..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/kiran.ramanna/Documents/github/2025stanford/005-module/module_5_large_embeddingv1_1_Tech103.ipynb#X13sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[31mTypeError\u001b[39m: set_css() takes 0 positional arguments but 1 was given"
          ]
        }
      ],
      "source": [
        "def simple_recursive_split(docs, chunk_size=1000, chunk_overlap=200, separators=None):\n",
        "    # Extract the main text and its associated metadata\n",
        "    text = docs[\"page_content\"]\n",
        "    metadata = docs[\"metadata\"]\n",
        "\n",
        "    # Set default separators if none are provided\n",
        "    if separators is None:\n",
        "        separators = [\"\\n\\n\", \"\\n\", \" \", \".\", \",\", \"\\uff0c\", \"\\u3001\", \"\\uff0e\", \"\\u3002\"]\n",
        "\n",
        "    # Helper function to recursively split text based on the separators\n",
        "    def split_with_separators(t):\n",
        "        # If the text is already within the chunk size, return it directly\n",
        "        if len(t) <= chunk_size:\n",
        "            return [t]\n",
        "\n",
        "        # Attempt splitting by each separator in order\n",
        "        for sep in separators:\n",
        "            if sep and sep in t:\n",
        "                parts = t.split(sep)\n",
        "                chunks = []\n",
        "                current = \"\"\n",
        "\n",
        "                # Build chunks without exceeding the maximum chunk size\n",
        "                for part in parts:\n",
        "                    part += sep  # Reattach the separator to preserve structure\n",
        "                    if len(current + part) <= chunk_size:\n",
        "                        current += part\n",
        "                    else:\n",
        "                        if current:\n",
        "                            chunks.append(current.strip())\n",
        "                        current = part  # Start a new chunk\n",
        "\n",
        "                # Add the final leftover chunk\n",
        "                if current:\n",
        "                    chunks.append(current.strip())\n",
        "\n",
        "                # Recursively re-split chunks that are still too large\n",
        "                result = []\n",
        "                for chunk in chunks:\n",
        "                    if len(chunk) > chunk_size:\n",
        "                        result.extend(split_with_separators(chunk))\n",
        "                    else:\n",
        "                        result.append(chunk)\n",
        "                return result\n",
        "\n",
        "        # Fallback: if no separators are effective, split the text by fixed character lengths\n",
        "        return [t[i:i + chunk_size] for i in range(0, len(t), chunk_size)]\n",
        "\n",
        "    # Split the original text\n",
        "    splits = split_with_separators(text)\n",
        "\n",
        "    # Add overlap between chunks to preserve context between adjacent segments\n",
        "    overlapped = []\n",
        "    for i, chunk in enumerate(splits):\n",
        "        if i == 0:\n",
        "            # First chunk, no overlap\n",
        "            overlapped.append({\n",
        "                \"page_content\": chunk,\n",
        "                \"metadata\": metadata\n",
        "            })\n",
        "        else:\n",
        "            # For subsequent chunks, add overlap from the end of the previous chunk\n",
        "            overlap = splits[i - 1][-chunk_overlap:]\n",
        "            overlapped.append({\n",
        "                \"page_content\": f\"{overlap} {chunk}\",\n",
        "                \"metadata\": metadata\n",
        "            })\n",
        "\n",
        "    return overlapped\n",
        "\n",
        "# Apply the chunking function to each document in the dataset\n",
        "# This flattens all chunks into a single list\n",
        "texts = [chunk for doc in data for chunk in simple_recursive_split(doc, 2048, 50)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "4e5PFukQEiTW",
        "outputId": "e7909d8b-3def-4f89-d066-49c0597e7132"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x106650b80> (for pre_run_cell), with arguments args (<ExecutionInfo object at 166145c10, raw_cell=\"print (f'You now have {len(texts)} document(s) in ..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/kiran.ramanna/Documents/github/2025stanford/005-module/module_5_large_embeddingv1_1_Tech103.ipynb#X14sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[31mTypeError\u001b[39m: set_css() takes 0 positional arguments but 1 was given"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You now have 22 document(s) in your data\n",
            "There are 1704 characters in your document\n"
          ]
        }
      ],
      "source": [
        "print (f'You now have {len(texts)} document(s) in your data')\n",
        "print (f'There are {len(texts[1][\"page_content\"])} characters in your document')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Hnxr21_EyCw"
      },
      "source": [
        "## Text Embedding Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "yD7a8lEFExEi",
        "outputId": "1aefde26-0e53-4cbb-eac5-aca23934a144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x106650b80> (for pre_run_cell), with arguments args (<ExecutionInfo object at 313781280, raw_cell=\"# Load embedding model from HuggingFace\n",
            "from trans..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/kiran.ramanna/Documents/github/2025stanford/005-module/module_5_large_embeddingv1_1_Tech103.ipynb#X16sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[31mTypeError\u001b[39m: set_css() takes 0 positional arguments but 1 was given"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "<All keys matched successfully>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 1.2799697   0.40158516 -3.5162659  -0.39813337  1.5919148 ]\n"
          ]
        }
      ],
      "source": [
        "# Load embedding model from HuggingFace\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "text_tokenizer = AutoTokenizer.from_pretrained(\"nomic-ai/nomic-embed-text-v1.5\", trust_remote_code=True)\n",
        "text_model = AutoModel.from_pretrained(\"nomic-ai/nomic-embed-text-v1.5\", trust_remote_code=True)\n",
        "\n",
        "# Function to generate embeddings from text\n",
        "def get_text_embeddings(text):\n",
        "    inputs = text_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    outputs = text_model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "    return embeddings[0].detach().numpy()\n",
        "\n",
        "# Example usage of the function\n",
        "text = \"This is a test sentence.\"\n",
        "\n",
        "# Get the embedding vector for the input text\n",
        "embeddings = get_text_embeddings(text)\n",
        "\n",
        "# Optionally, get the length of the embedding (number of dimensions)\n",
        "text_embeddings_size = len(embeddings)\n",
        "\n",
        "# Print the first 5 values of the embedding vector for inspection\n",
        "print(embeddings[:5])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "PY7ArMe1E6F6",
        "outputId": "12db229d-2ec3-465c-cfc4-10bcc392c67f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x106650b80> (for pre_run_cell), with arguments args (<ExecutionInfo object at 3497aeab0, raw_cell=\"# Generate embeddings for all chunks\n",
            "text_embeded ..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/kiran.ramanna/Documents/github/2025stanford/005-module/module_5_large_embeddingv1_1_Tech103.ipynb#X20sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[31mTypeError\u001b[39m: set_css() takes 0 positional arguments but 1 was given"
          ]
        }
      ],
      "source": [
        "# Generate embeddings for all chunks\n",
        "text_embeded = [get_text_embeddings(document[\"page_content\"]) for document in texts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXheX7UrFvQJ"
      },
      "source": [
        "## Qdrant VectorDatabase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "__bhmEsrFyT-",
        "outputId": "668e01f1-10e8-4411-edf6-a423c7ea0a73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x106650b80> (for pre_run_cell), with arguments args (<ExecutionInfo object at 34995f650, raw_cell=\"# Import necessary modules from the Qdrant client ..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/kiran.ramanna/Documents/github/2025stanford/005-module/module_5_large_embeddingv1_1_Tech103.ipynb#X22sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[31mTypeError\u001b[39m: set_css() takes 0 positional arguments but 1 was given"
          ]
        },
        {
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import necessary modules from the Qdrant client library\n",
        "# Qdrant is a vector database that allows you to store and search high-dimensional vector embeddings efficiently\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "# Create a new Qdrant client instance using in-memory storage\n",
        "# \":memory:\" means the data will be stored temporarily in RAM (not saved to disk)\n",
        "# Useful for testing or prototyping — everything is wiped when the program ends\n",
        "client = QdrantClient(\":memory:\")\n",
        "\n",
        "# Display the size (number of dimensions) of the text embeddings we generated earlier\n",
        "# This is important because Qdrant needs to know the exact size of each vector to create a collection\n",
        "text_embeddings_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "xMsymZ6sF15X",
        "outputId": "2d5b9ba8-a7ba-4abf-aeeb-f2cc06d11e9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x106650b80> (for pre_run_cell), with arguments args (<ExecutionInfo object at 34eaaf0e0, raw_cell=\"# Check if a collection named \"demo_collection\" al..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/kiran.ramanna/Documents/github/2025stanford/005-module/module_5_large_embeddingv1_1_Tech103.ipynb#X23sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[31mTypeError\u001b[39m: set_css() takes 0 positional arguments but 1 was given"
          ]
        }
      ],
      "source": [
        "# Check if a collection named \"demo_collection\" already exists in Qdrant\n",
        "# A collection is like a table in a database — it stores a set of vectors and associated metadata\n",
        "if not client.collection_exists(\"demo_collection\"):  # Creating the collection only if it doesn't exist\n",
        "\n",
        "    # Create a new collection in Qdrant\n",
        "    client.create_collection(\n",
        "        collection_name=\"demo_collection\",  # Name of the collection (you can choose any name)\n",
        "\n",
        "        # Define the configuration for the vectors that will be stored in this collection\n",
        "        vectors_config=models.VectorParams(\n",
        "            size=text_embeddings_size,       # The size (number of dimensions) of the vectors, must match your model's output\n",
        "            distance=models.Distance.COSINE  # Use cosine similarity for comparing vectors (good for text embeddings)\n",
        "        ),\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "WuZnPbMdF48F",
        "outputId": "2ef0b0aa-2db6-48d4-c659-cfc2b4de8f7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x106650b80> (for pre_run_cell), with arguments args (<ExecutionInfo object at 34995f650, raw_cell=\"\n",
            "# Import the `uuid4` function to generate unique ..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/kiran.ramanna/Documents/github/2025stanford/005-module/module_5_large_embeddingv1_1_Tech103.ipynb#X24sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[31mTypeError\u001b[39m: set_css() takes 0 positional arguments but 1 was given"
          ]
        }
      ],
      "source": [
        "\n",
        "# Import the `uuid4` function to generate unique IDs for each vector\n",
        "# These IDs help identify and retrieve individual points later\n",
        "from uuid import uuid4\n",
        "\n",
        "# Import NumPy to handle vector data formats (embeddings are stored as NumPy arrays)\n",
        "import numpy as np\n",
        "\n",
        "# Upload all our text embeddings to the \"demo_collection\" in Qdrant\n",
        "client.upload_points(\n",
        "    collection_name=\"demo_collection\",  # Target collection where we want to store our vectors\n",
        "\n",
        "    # Create a list of PointStruct objects, one for each text chunk\n",
        "    points=[\n",
        "        models.PointStruct(\n",
        "            id=str(uuid4()),  # Generate a unique ID for each point (as a string)\n",
        "\n",
        "            # Convert the embedding to a NumPy array, which is the expected format\n",
        "            vector=np.array(text_embeded[idx]),\n",
        "\n",
        "            # Attach payload — additional information stored with each vector\n",
        "            # This allows us to retrieve the original text and its metadata later\n",
        "            payload={\n",
        "                \"metadata\": doc[\"metadata\"],         # Source and row info\n",
        "                \"content\": doc[\"page_content\"]       # The full text chunk\n",
        "            }\n",
        "        )\n",
        "        for idx, doc in enumerate(texts)  # Loop through all texts and match them to their embeddings\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zphjkhQTGE4U",
        "outputId": "58319d91-0b53-43d7-c938-f5df2049e2c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function set_css at 0x106650b80> (for pre_run_cell), with arguments args (<ExecutionInfo object at 34eb7c620, raw_cell=\"# Import the Google Drive integration module for G..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/kiran.ramanna/Documents/github/2025stanford/005-module/module_5_large_embeddingv1_1_Tech103.ipynb#X25sZmlsZQ%3D%3D>,),kwargs {}:\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "set_css() takes 0 positional arguments but 1 was given",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[31mTypeError\u001b[39m: set_css() takes 0 positional arguments but 1 was given"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Import the Google Drive integration module for Google Colab\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Mount your Google Drive to the Colab environment\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# This allows you to read from and write to files stored in your Drive\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# After running this, a link will appear asking for permission to access your Drive\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Once authorized, your Drive will be available under '/content/drive'\u001b[39;00m\n\u001b[32m      8\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "# Import the Google Drive integration module for Google Colab\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount your Google Drive to the Colab environment\n",
        "# This allows you to read from and write to files stored in your Drive\n",
        "# After running this, a link will appear asking for permission to access your Drive\n",
        "# Once authorized, your Drive will be available under '/content/drive'\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08yXLAhgGLzL"
      },
      "outputs": [],
      "source": [
        "# Import necessary modules from the Qdrant client\n",
        "# QdrantClient lets us interact with the Qdrant vector database\n",
        "# models is used for configuring vectors and managing points\n",
        "from qdrant_client import QdrantClient, models\n",
        "\n",
        "# Import the os module to work with the file system (for creating directories, etc.)\n",
        "import os\n",
        "\n",
        "# Define the local directory where Qdrant will store its data files\n",
        "# This path is inside the Colab environment (or Google Drive if mounted)\n",
        "qdrant_data_dir = '/content/drive/MyDrive/Semantic_Search/qdrant_data'\n",
        "\n",
        "# Create the directory if it doesn't already exist\n",
        "# This ensures Qdrant has a place to store persistent data like vectors and collections\n",
        "os.makedirs(qdrant_data_dir, exist_ok=True)\n",
        "\n",
        "# Initialize the Qdrant client and set its storage location to the directory we just created\n",
        "# This will persist your Qdrant data (e.g., vector collections) to disk instead of just in memory\n",
        "client = QdrantClient(path=qdrant_data_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "WQoHYriLGWtq",
        "outputId": "3631f70a-86e2-4cd9-815d-d40f01af2dcf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "      pre {\n",
              "          white-space: pre-wrap;  /* Enable word-wrapping in code/output blocks */\n",
              "      }\n",
              "    </style>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Check if a collection named \"demo_collection\" already exists in Qdrant\n",
        "# A collection is like a table in a database — it stores a set of vectors and associated metadata\n",
        "if not client.collection_exists(\"demo_collection\"):  # Creating the collection only if it doesn't exist\n",
        "\n",
        "    # Create a new collection in Qdrant\n",
        "    client.create_collection(\n",
        "        collection_name=\"demo_collection\",  # Name of the collection (you can choose any name)\n",
        "\n",
        "        # Define the configuration for the vectors that will be stored in this collection\n",
        "        vectors_config=models.VectorParams(\n",
        "            size=text_embeddings_size,       # The size (number of dimensions) of the vectors, must match your model's output\n",
        "            distance=models.Distance.COSINE  # Use cosine similarity for comparing vectors (good for text embeddings)\n",
        "        ),\n",
        "    )\n",
        "\n",
        "# Import the `uuid4` function to generate unique IDs for each vector\n",
        "# These IDs help identify and retrieve individual points later\n",
        "from uuid import uuid4\n",
        "\n",
        "# Import NumPy to handle vector data formats (embeddings are stored as NumPy arrays)\n",
        "import numpy as np\n",
        "\n",
        "# Upload all our text embeddings to the \"demo_collection\" in Qdrant\n",
        "client.upload_points(\n",
        "    collection_name=\"demo_collection\",  # Target collection where we want to store our vectors\n",
        "\n",
        "    # Create a list of PointStruct objects, one for each text chunk\n",
        "    points=[\n",
        "        models.PointStruct(\n",
        "            id=str(uuid4()),  # Generate a unique ID for each point (as a string)\n",
        "\n",
        "            # Convert the embedding to a NumPy array, which is the expected format\n",
        "            vector=np.array(text_embeded[idx]),\n",
        "\n",
        "            # Attach payload — additional information stored with each vector\n",
        "            # This allows us to retrieve the original text and its metadata later\n",
        "            payload={\n",
        "                \"metadata\": doc[\"metadata\"],         # Source and row info\n",
        "                \"content\": doc[\"page_content\"]       # The full text chunk\n",
        "            }\n",
        "        )\n",
        "        for idx, doc in enumerate(texts)  # Loop through all texts and match them to their embeddings\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHtM0SGyF9Kz"
      },
      "source": [
        "## Run Query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KRpWsEnpF79Y",
        "outputId": "21779bde-613e-43fe-d346-052608b4d5b6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "      pre {\n",
              "          white-space: pre-wrap;  /* Enable word-wrapping in code/output blocks */\n",
              "      }\n",
              "    </style>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create a query vector by embedding a sample search string\n",
        "# This string represents what you're looking for — in this case, something about \"Democrats challenges in Senate\"\n",
        "# The result is a vector in the same format as the ones stored in the Qdrant collection\n",
        "query = get_text_embeddings('Democrats challenges in Senate')\n",
        "\n",
        "# Perform a similarity search in Qdrant using the query vector\n",
        "# This finds the most relevant text chunks (based on vector similarity)\n",
        "text_hits = client.query_points(\n",
        "    collection_name=\"demo_collection\",  # The name of the collection where vectors were stored\n",
        "    query=query,                         # The query vector — what we want to find similar results to\n",
        "    limit=3,                             # Limit the number of results to 3 most relevant chunks\n",
        ").points                                 # Extract only the list of matching points (each with vector + payload)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "8AU_jZE9IjLv",
        "outputId": "b43230f6-f89b-48d3-a82d-0bc716df7e32"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "      pre {\n",
              "          white-space: pre-wrap;  /* Enable word-wrapping in code/output blocks */\n",
              "      }\n",
              "    </style>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "[ScoredPoint(id='a9b0db57-6858-4b37-844f-0d90f2aeb7bb', version=0, score=0.6620315493425604, payload={'metadata': {'source': 'Are The Democrats Screwed In The Senate After 2024?'}, 'content': \"airly competitive race against Mike Lee this year. Even with an additional senator going into 2023, the 2024 map is still so bad for Democrats that keeping the Senate for years to come will be a fairly tough order. The party’s prospects might rest more upon limiting the damage in 2024 so that it has a chance to regain the Senate in 2026 or 2028. But a bad 2024 could make it very difficult for Democrats to regain the Senate before 2030 or 2032.\\nThat bleak picture may shape the next few years of political maneuvering. When Vox’s Dylan Matthews suggested on Twitter that liberal Justices Sonia Sotomayor (age 68) and Elena Kagan (age 62) should retire while Democrats have their Senate majority and be replaced by younger justices, it didn’t go over well. But it’s a perfectly rational suggestion if Democrats don’t feel like gambling with their judicial future. (Consider how consequential Ruth Bader Ginsburg’s decision not to retire has been for liberals.) Democrats have a narrow path to Senate control after 2024, but it’s narrow indeed, and one that might require the GOP continuing to nominate bad candidates — and a fair share of luck. url: https://fivethirtyeight.com/features/democrats-senate-chances-2024-and-beyond/ categories: ['news']\"}, vector=None, shard_key=None, order_value=None),\n",
              " ScoredPoint(id='976e8a5a-eaf0-4c70-b164-6737d5036076', version=0, score=0.6620315493425604, payload={'metadata': {'source': 'Are The Democrats Screwed In The Senate After 2024?'}, 'content': \"airly competitive race against Mike Lee this year. Even with an additional senator going into 2023, the 2024 map is still so bad for Democrats that keeping the Senate for years to come will be a fairly tough order. The party’s prospects might rest more upon limiting the damage in 2024 so that it has a chance to regain the Senate in 2026 or 2028. But a bad 2024 could make it very difficult for Democrats to regain the Senate before 2030 or 2032.\\nThat bleak picture may shape the next few years of political maneuvering. When Vox’s Dylan Matthews suggested on Twitter that liberal Justices Sonia Sotomayor (age 68) and Elena Kagan (age 62) should retire while Democrats have their Senate majority and be replaced by younger justices, it didn’t go over well. But it’s a perfectly rational suggestion if Democrats don’t feel like gambling with their judicial future. (Consider how consequential Ruth Bader Ginsburg’s decision not to retire has been for liberals.) Democrats have a narrow path to Senate control after 2024, but it’s narrow indeed, and one that might require the GOP continuing to nominate bad candidates — and a fair share of luck. url: https://fivethirtyeight.com/features/democrats-senate-chances-2024-and-beyond/ categories: ['news']\"}, vector=None, shard_key=None, order_value=None),\n",
              " ScoredPoint(id='6471d89c-1601-413e-848b-7c50b67ba6bc', version=0, score=0.6620315493425604, payload={'metadata': {'source': 'Are The Democrats Screwed In The Senate After 2024?'}, 'content': \"airly competitive race against Mike Lee this year. Even with an additional senator going into 2023, the 2024 map is still so bad for Democrats that keeping the Senate for years to come will be a fairly tough order. The party’s prospects might rest more upon limiting the damage in 2024 so that it has a chance to regain the Senate in 2026 or 2028. But a bad 2024 could make it very difficult for Democrats to regain the Senate before 2030 or 2032.\\nThat bleak picture may shape the next few years of political maneuvering. When Vox’s Dylan Matthews suggested on Twitter that liberal Justices Sonia Sotomayor (age 68) and Elena Kagan (age 62) should retire while Democrats have their Senate majority and be replaced by younger justices, it didn’t go over well. But it’s a perfectly rational suggestion if Democrats don’t feel like gambling with their judicial future. (Consider how consequential Ruth Bader Ginsburg’s decision not to retire has been for liberals.) Democrats have a narrow path to Senate control after 2024, but it’s narrow indeed, and one that might require the GOP continuing to nominate bad candidates — and a fair share of luck. url: https://fivethirtyeight.com/features/democrats-senate-chances-2024-and-beyond/ categories: ['news']\"}, vector=None, shard_key=None, order_value=None)]"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_hits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDB9urV-IxM0"
      },
      "source": [
        "## We can start from here now!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3mNj8OjuZ7t",
        "outputId": "0eb40190-ee38-4480-f68f-dfeb7f2536fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting qdrant_client\n",
            "  Downloading qdrant_client-1.14.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.11/dist-packages (from qdrant_client) (1.71.0)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant_client) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from qdrant_client) (2.0.2)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant_client)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.11/dist-packages (from qdrant_client) (5.29.4)\n",
            "Requirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from qdrant_client) (2.11.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.11/dist-packages (from qdrant_client) (2.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant_client) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (4.13.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant_client) (0.4.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant_client) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant_client) (1.3.1)\n",
            "Downloading qdrant_client-1.14.2-py3-none-any.whl (327 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.7/327.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: portalocker, qdrant_client\n",
            "Successfully installed portalocker-2.10.1 qdrant_client-1.14.2\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.76.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install qdrant_client\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_Z1dKSzu4Rg"
      },
      "outputs": [],
      "source": [
        "# Import the Google Drive integration module for Google Colab\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount your Google Drive to the Colab environment\n",
        "# This allows you to read from and write to files stored in your Drive\n",
        "# After running this, a link will appear asking for permission to access your Drive\n",
        "# Once authorized, your Drive will be available under '/content/drive'\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf7NR5nMI1N8"
      },
      "outputs": [],
      "source": [
        "# Import the main Qdrant client class to connect and interact with a Qdrant vector database\n",
        "from qdrant_client import QdrantClient\n",
        "\n",
        "# Import specific classes used to configure how vectors are stored and compared in a collection\n",
        "from qdrant_client.http.models import Distance, VectorParams\n",
        "\n",
        "# Import the `userdata` module from Google Colab.\n",
        "from google.colab import userdata\n",
        "\n",
        "# This is used to send requests to OpenRouter, which gives access to various LLMs (large language models)\n",
        "from openai import OpenAI\n",
        "\n",
        "# Import HTML and display tools from IPython\n",
        "# These allow you to inject custom HTML or CSS into the notebook\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# Import necessary classes from the Hugging Face Transformers library\n",
        "# AutoTokenizer handles breaking text into tokens\n",
        "# AutoModel loads the pre-trained model used to compute vector embeddings\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Import the openai\n",
        "\n",
        "import openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4MxRUrZJNI8"
      },
      "source": [
        "**1. Define the Qdrant client first to connect to the vector database.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YfmVtDMKI6u8"
      },
      "outputs": [],
      "source": [
        "# Attempt to initialize the Qdrant client\n",
        "try:\n",
        "    # Initialize the Qdrant client and set its storage path\n",
        "    # This stores and retrieves the vector database in the specified directory on disk\n",
        "    client = QdrantClient(path='/content/drive/MyDrive/Semantic_Search/qdrant_data')\n",
        "\n",
        "except RuntimeError as e:\n",
        "    # Catch the specific error that occurs when the Qdrant client is already running with this path\n",
        "    if \"already accessed by another instance\" in str(e):\n",
        "        print(\"Qdrant is already initialized with this path in the current session.\")\n",
        "        print(\"You don't need to create the client again — reuse the existing one.\")\n",
        "    else:\n",
        "        # Re-raise the error if it's something else\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD5WB-pIJQ3l"
      },
      "source": [
        "**2. Define the OpenRouter client to serve as the language model (LLM) for the pipeline.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhoJnpq1JSuL"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Retrieve the value of a saved environment variable named 'OPEN_ROUTER_API_KEY'.\n",
        "\n",
        "OPEN_ROUTER_API_KEY = userdata.get('OPEN_ROUTER_API_KEY')\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the OpenAI-compatible client, but point it to OpenRouter's API instead of OpenAI's\n",
        "# OpenRouter is a gateway to multiple LLMs like GPT, Claude, Mistral, and others, through one unified API\n",
        "\n",
        "open_router_client = OpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",  # Set the API endpoint to OpenRouter (not OpenAI)\n",
        "    api_key=OPEN_ROUTER_API_KEY               # Use your OpenRouter API key for authentication\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBxyUf2HJZqL"
      },
      "source": [
        "**3. Import the same embedding model used during vector database creation to ensure consistency.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454,
          "referenced_widgets": [
            "0da3450aef084297a87ca27b5f3b7455",
            "0e305e64e68c4cb8bdbb5b220b4da828",
            "8e80335c0d474855b5654be48555bc05",
            "8d717204cab04451ad1226d800503169",
            "9b824fb8720d46d59adbf4c5d9ed445a",
            "642e221cb1fc4b04a76a327a1ef8d926",
            "32db8a4aa90a449093b1a455ba5200da",
            "91a98acbe6714b909fa660244da7d35f",
            "7a027b73a9c34f0d8b739f9ddf60e59e",
            "bbad5107b38a4303bbe014e791c520fd",
            "9b77a6bfb1644c4e9abf47f729aa185e",
            "f034561e6d0e4ad6a67d68cf9a3899e5",
            "a4487c00ed054ad9b326449607b73b20",
            "015ff099ca4b477b9fc4e484db77f330",
            "ad7b87183aa54bb69669ba6d77b77f8c",
            "383b9bdbf235450ba24127329f4c3055",
            "8c6f329aa3584359b6f1ed053b4eded6",
            "67ba4db660e34ac296a3cd782b785d89",
            "91e0d2d163a94e6e817ec2776bde8a7a",
            "a87406edcb354e798e81784b49e16f15",
            "5560c904fb504690aa66860f3ea5e299",
            "caec68596530403c8dc4beeb69b80165",
            "e9e35cbefa184a3ebad647a638058ebb",
            "76fd05fbe15e4d83b0410e2e081b5824",
            "6d0d1c53599b45279453ccaf390e08e5",
            "c3c0583f9f314adcbc3d1e6c0d9e412b",
            "68e78e9e9d174466a17f53cc66896c4a",
            "cb72465fcb7443fda7b9a13dbe161fdd",
            "0e84768499c74d809a1a4bc89df8493f",
            "7e1e4ddf68994b30bbb3bd1976a2590e",
            "7a888c823fc44e1fa989cf55517ae28b",
            "b79cf41efaba4123bf69674d31a46428",
            "f19f6758c2854065a696e010d8a24f59",
            "aaa66d0338584cf68402e9170ede6a43",
            "cd29a5d1d5ed4bf8b4f09da5ec762cd4",
            "549ceb46221747b785286ed66217e734",
            "28ed36d1e5de4aac882fe4cf3c9dccc7",
            "45831dc836b54ab38892d1f134feb712",
            "73f72dcae0424e56b9a9fbac09eb099b",
            "49530a8c740f481fbaf1d7d731c135d0",
            "5071019c68f8495fb419a4526eb49fdd",
            "8eb1cef2dd53435a9afe03dc87d473d2",
            "1d6d7018d3744de2ac21f426030ce2e6",
            "d7da4d7caa464789a74d29611c19ab52",
            "80bc061644ee4b5a807070c5eef483d9",
            "5e328da6d36b4fb3b3cc0bd4c2740482",
            "5b9c5f7cfefc4199b6bcb9ab342843f2",
            "8e647bfd40304cccb6da9101673260ce",
            "1f4c8cd8e700490791def2a9b434ecf6",
            "66940d4565b744a08c0d03ab036e9c31",
            "b6da49162669458195d988c816b05283",
            "484ee07ba9c84306be862601b18bd4f3",
            "51eefd0687fa48199eb82e378b0a04f6",
            "64ebfd52cd5c4a9eb928368c4fe782c7",
            "f82260623c3b452fbd4f25b4eea122c0",
            "bb14933f64a747229b490f6915fa3107",
            "da4db2195578448ea94bb71618aac853",
            "eb7c4edeac6843dfb8bb2d0e6412d376",
            "b0974d11f54f40528947ea92cfb5e467",
            "4e5149ea6c3e4b679a99cbaeaa204198",
            "ba9625d4c9c943cfa487f001f44759e8",
            "bc8f5eaf8e724078b785aec8620303cc",
            "182b5d77998c43cda26c8bf442881780",
            "ededa41d1e054083956c19e46e4866bf",
            "22a7901cd876417089869865201bfc56",
            "072637dcdb144cbdb3d02146bb62a6b7",
            "f2e5368962d04b66bcad044b78ee569b",
            "c3c4b933e7be4e22bbf4450dd982eeb0",
            "4f75d233562142608e848df70a578b6d",
            "8f9a66713b344c27b6af1d017966bce1",
            "667e57c917654d0995c1814d3ef9859b",
            "398b3a390a3c4f7b8d80d740053c5d0d",
            "6e5b29d9a6ec4259b573829517d7966c",
            "f922a9a5d2de4a918e06cfd7e6f463e2",
            "b54ea46ea2a6463b9f51db677bd19455",
            "f958abd6a3244a1ea0648d49406bc229",
            "4bda983f76ca406b9e7aaaf17ddfcd2c",
            "93aada13a77e49638b4839c629c213d8",
            "526b8e549ae84121b694b188cc67dd6c",
            "b665d5ea3b2d4e3c91753189b7825f30",
            "025a8a6df2bd40b59bf076dd15d1cef0",
            "9000a470f62c46e383414ea4d73a9edf",
            "872405ea1c21471a8ce7d616f0d60d4b",
            "b69105d0c1144b92ad4e0fa1311fa376",
            "56812bfabd2c42ac85afc79a7fbd6b19",
            "ea1d77a9fb504379979403c8d00fb315",
            "55885ef6e8f74b1bbf73f08a8d156abb",
            "46570d5e1c244a31b401d2424c3010f5"
          ]
        },
        "id": "8sUJ24smJYl-",
        "outputId": "63c36426-f182-4509-fb9b-e5a36d095029"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0da3450aef084297a87ca27b5f3b7455",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.19k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f034561e6d0e4ad6a67d68cf9a3899e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9e35cbefa184a3ebad647a638058ebb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aaa66d0338584cf68402e9170ede6a43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80bc061644ee4b5a807070c5eef483d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/2.06k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb14933f64a747229b490f6915fa3107",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "configuration_hf_nomic_bert.py:   0%|          | 0.00/1.96k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/nomic-ai/nomic-bert-2048:\n",
            "- configuration_hf_nomic_bert.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2e5368962d04b66bcad044b78ee569b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modeling_hf_nomic_bert.py:   0%|          | 0.00/104k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/nomic-ai/nomic-bert-2048:\n",
            "- modeling_hf_nomic_bert.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93aada13a77e49638b4839c629c213d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/547M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:transformers_modules.nomic-ai.nomic-bert-2048.7710840340a098cfb869c4f65e87cf2b1b70caca.modeling_hf_nomic_bert:<All keys matched successfully>\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Load a pre-trained tokenizer and model designed for generating text embeddings\n",
        "# \"nomic-ai/nomic-embed-text-v1.5\" is a model specifically trained to turn text into high-quality vector representations\n",
        "# trust_remote_code=True allows use of any custom logic included with the model\n",
        "text_tokenizer = AutoTokenizer.from_pretrained(\"nomic-ai/nomic-embed-text-v1.5\", trust_remote_code=True)\n",
        "text_model = AutoModel.from_pretrained(\"nomic-ai/nomic-embed-text-v1.5\", trust_remote_code=True)\n",
        "\n",
        "# Define a function to convert input text into a fixed-size vector (embedding)\n",
        "def get_text_embeddings(text):\n",
        "    # Tokenize the input text and return it as PyTorch tensors\n",
        "    # padding=True: pad shorter sequences to ensure consistent length\n",
        "    # truncation=True: cut off text that is too long for the model\n",
        "    inputs = text_tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Pass the tokenized input through the model to obtain output embeddings\n",
        "    outputs = text_model(**inputs)\n",
        "\n",
        "    # outputs.last_hidden_state contains embeddings for each token\n",
        "    # We take the mean across all tokens to get a single vector for the entire text\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)\n",
        "\n",
        "    # Convert the result to a NumPy array and remove it from the computation graph\n",
        "    return embeddings[0].detach().numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF8CSOOLJq3O"
      },
      "source": [
        "**4. Test the retrieval functions to ensure they're returning relevant results.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1z2-94sJrNy"
      },
      "outputs": [],
      "source": [
        "query = \"\"\"Democrats challenges in Senate\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0eluiVpJvbD"
      },
      "outputs": [],
      "source": [
        "# get query embedded\n",
        "query_em = get_text_embeddings(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNg2cn_8JxVq"
      },
      "outputs": [],
      "source": [
        "text_hits = client.query_points(\n",
        "        collection_name=\"demo_collection\",\n",
        "        query=query_em,\n",
        "        limit=10,\n",
        "    ).points\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWbD5XYlJ0BW"
      },
      "outputs": [],
      "source": [
        "# Extract the original text content from each result returned by the similarity search\n",
        "# `text_hits` is a list of points returned by Qdrant's query\n",
        "# Each point has a `payload`, which contains metadata and the original text chunk\n",
        "\n",
        "contents = [point.payload['content'] for point in text_hits]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRvPG59IJ2wJ",
        "outputId": "e69f266c-c1a3-439b-d631-3d9204c0e657"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"airly competitive race against Mike Lee this year. Even with an additional senator going into 2023, the 2024 map is still so bad for Democrats that keeping the Senate for years to come will be a fairly tough order. The party’s prospects might rest more upon limiting the damage in 2024 so that it has a chance to regain the Senate in 2026 or 2028. But a bad 2024 could make it very difficult for Democrats to regain the Senate before 2030 or 2032.\\nThat bleak picture may shape the next few years of political maneuvering. When Vox’s Dylan Matthews suggested on Twitter that liberal Justices Sonia Sotomayor (age 68) and Elena Kagan (age 62) should retire while Democrats have their Senate majority and be replaced by younger justices, it didn’t go over well. But it’s a perfectly rational suggestion if Democrats don’t feel like gambling with their judicial future. (Consider how consequential Ruth Bader Ginsburg’s decision not to retire has been for liberals.) Democrats have a narrow path to Senate control after 2024, but it’s narrow indeed, and one that might require the GOP continuing to nominate bad candidates — and a fair share of luck. url: https://fivethirtyeight.com/features/democrats-senate-chances-2024-and-beyond/ categories: ['news']\",\n",
              " '_id: 63927168098523fa9d5ef047 title: Are The Democrats Screwed In The Senate After 2024? author: Nate Silver publish_date: 1670515535000.0 full_text: \\n\\n\\n\\n2028 Election\\nAre The Democrats Screwed In The Senate After 2024?\\nNo, but the party faces an uphill battle.\\n\\n\\n\\nBy Nate Silver\\n\\n\\nDec. 8, 2022, at 11:05 AM\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSamuel Corum / Getty Images',\n",
              " 'which there’s typically some chance of retirement. Democrats also have a below-the-radar pickup opportunity in Alaska, where Mary Peltola was elected to a full term in the U.S. House10 last month by a 10-point margin after ranked-choice votes were tabulated. GOP incumbent Dan Sullivan has a mediocre approval rating and a Peltola-Sullivan race would potentially be competitive.\\nSuppose, though, that Democrats win the presidency but lose the Senate in 2024. It’s really not as crazy as it sounds. If every state votes identically to how it did in the 2020 presidential election — and every Senate race follows the presidential vote — then Democrats would come out of 2024 with the presidency but only 48 Senate seats after losing West Virginia, Montana and Ohio. Could Democrats pick up two Senate seats from the GOP in the 2026 midterm while controlling the presidency? Unlikely — but then again, Democrats gaining Senate seats this year seemed unlikely and they did it.\\n2028\\nRepublican pickup opportunities\\nPlatinum tier: None\\nGold tier: Nevada (Cortez Masto), Pennsylvania (Fetterman), Arizona (Kelly), Georgia (Warnock) \\nSilver tier: New Hampshire (Hassan)\\nBronze tier: Oregon (Wyden)\\nAll right, now we’re literally coming full circle to consider the races that were just contested in last month’s midterm. So we’ll keep it pretty brief. Yes, Democrats have to feel pretty good about their wins in Nevada, Pennsylvania, Arizona and Georgia — especially given that the overall political environment wasn’t that great for Democrats this year. But they were narrow wins, and (with the possible exception of Nevada) they came against a mediocre set of GOP opponents. Maybe some of these races are toward the silver end of the gold tier, but more likely than not they’ll be competitive again.',\n",
              " '5 AM\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSamuel Corum / Getty Images I’m not that impressed by long-term projections of Democratic doom in the Senate. Mostly that’s because I’m not that impressed by long-term political projections in general. Political coalitions change; not many people would have had it on their bingo card that Democrats would obtain a Senate majority in 2020 by winning two runoffs in Georgia, and then would actually expand on that majority in 2022 following another runoff in Georgia despite their party controlling the White House.\\nWith that said, while I don’t think we can say very much about what politics will look like 10 or 20 years from now, a medium-term look-ahead is possible. Do Democrats have a reasonable hope of regaining a trifecta — control of the House, Senate and presidency — at any point in the near future (2024, 2026 or 2028)? And how long will they hold onto control of the Senate and the presidency, allowing them to appoint Supreme Court justices without Republican help?\\nMy colleague Geoffrey Skelley already took an initial look at the 2024 Senate map, which is bad for Democrats, but I wanted to dig slightly deeper and also consider 2026 and 2028. Like Geoffrey, I’ll be focused on the Senate, because that’s the weakest link in Democrats’ effort to win back the trifecta. Despite some disadvantages in the Electoral College, Democrats obviously have no trouble winning the presidency. And they nearly held onto the House this year despite losing the popular vote for the House. The current House map doesn’t have much — if any — of a Republican skew, and Democrats should be able to win back the House if the national political environment is reasonably good for them.',\n",
              " 'e in these states — toward Republicans since then. I don’t want to focus too much on any one individual race, but it’s probably safe to assume that Joe Manchin has the toughest reelection campaign of all. Meanwhile, maybe Sherrod Brown can feel a bit more comfortable following Tim Ryan’s relatively good performance in Ohio this year, but Ryan did lose, and Brown may face a tougher opponent than Ryan did in J.D. Vance. Democrats also run the risk of retirements here; neither Manchin nor Jon Tester has officially yet announced they will seek reelection.\\nBeyond the platinum tier, Democrats face some other risks. Kyrsten Sinema is likely to face a serious primary challenge. Democrats keep winning close races for Congress in Nevada but it’s a very purple state. Tammy Baldwin, Debbie Stabenow and Bob Casey won by fairly comfortable margins in 2018 and will likely be fine in the event of a decent-to-good Democratic year, but if 2024 turns into a good Republican year, they could be in trouble.\\nDemocratic pickup opportunities\\nPlatinum tier: None\\nGold tier: None\\nSilver tier: Texas (Cruz), Florida (Scott)\\nBronze tier: None\\nConversely, it’s very slim pickings for Democrats. On paper, you’d think that Texas might be close — Ted Cruz won by less than 3 percentage points there in 2018 and Texas is more competitive than it once was — but the erosion of the Democratic vote in South Texas has prevented Texas from turning truly purple. And although Scott won by only 0.12 percentage points in 2018, Republicans did so well in Florida in 2020 and 2022 that I was tempted to demote his race all the way to the bronze tier. Plus, there’s a good chance that the GOP’s 2024 nominee will be either Florida Gov. Ron DeSantis or Florida resident Donald Trump, which could help drive Republican turnout.\\nBeyond that, any other races look like an extreme stretch for Democrats. Maybe Josh Hawley in Missouri could be vulnerable in a 2018-type environment, but that’s less likely in a presidential year and Hawley’s approval rating isn’t that bad. Put him in the “honorable mention” tier, I guess.',\n",
              " ' Put him in the “honorable mention” tier, I guess. Given all this, I’d imagine the modal outcome from 2024 is something like Republicans picking up about three Senate seats. There’s uncertainty around that; it’s surely within the realm of possibility that Democrats hold the Senate, but it’s also possible that Republicans could wind up with 54 or 55 seats. And of course, all of these races are correlated. If the GOP is doing well enough to win the presidency in 2024, they should have no trouble also winning the Senate.9\\n2026\\nRepublican pickup opportunities\\xa0\\nPlatinum tier: None\\nGold tier: Georgia (Ossoff), Michigan (Peters)\\nSilver tier: New Hampshire (Shaheen)\\nBronze tier: Minnesota (Smith), Virginia (Warner)\\nThe 2026 map is more balanced. Democrats undoubtedly feel pretty good about how they’ve performed in Georgia and Michigan in the past two cycles, but Jon Ossoff and Gary Peters won by extremely narrow margins in 2020 and it would be a mistake to assume they’re safe. It’s not a particularly deep set of pickup opportunities for Republicans, though if Democrats retain the presidency in 2024, you’d expect Republicans to have good midterms in 2026, and New Hampshire and perhaps even Minnesota and Virginia could potentially be in play.\\xa0\\nDemocratic pickup opportunities\\xa0\\nPlatinum tier: None\\nGold tier: Maine (Collins), North Carolina (Tillis)\\nSilver tier: Alaska (Sullivan)\\nBronze tier: Texas (Cornyn), Iowa (Ernst)\\nMeanwhile, Democrats will try again in the two states that were most disappointing to them in 2020: Maine and North Carolina. Given all the focus on Georgia, I wonder if North Carolina hasn’t become underrated as a place where Democrats could gain ground in the future; the states are fairly similar demographically and it wouldn’t take that much of a shift for Democrats to go from narrowly losing races in North Carolina to narrowly winning them. Susan Collins will be 74 years old in 2026, meanwhile, an age at which there’s typically some chance of retirement.',\n",
              " 'political environment is reasonably good for them. So let’s look at the 2024, 2026 and 2028 Senate maps (yes, 2028 features the same map as the midterm we just finished; I just can’t let go, I guess). We’ll classify races into bronze, silver, gold and platinum “tiers” in terms of how feasible they are as pickup opportunities. I’m deliberately using this goofy metallurgical theme as opposed to the categories FiveThirtyEight typically uses (e.g., “toss-up,” “lean Republican”) so you’ll recognize these as being back-of-the-envelope suppositions rather than any sort of official race ratings. \\nIn general, these ratings lean heavily on looking at how close a race was the last time it was contested, with some subjective adjustments for candidate quality. I’m also considering how the electoral environment has shifted within the state — Florida has gotten redder since Rick Scott was elected in 2018, for instance — although it is definitely not always safe to assume a state will continue trending in the same direction.\\n2024\\nRepublican pickup opportunities\\nPlatinum tier: West Virginia (Manchin), Montana (Tester), Ohio (Brown), \\nGold tier: Arizona (Sinema), Nevada (Rosen)\\nSilver tier: Wisconsin (Baldwin), Michigan (Stabenow), Pennsylvania (Casey)\\nBronze tier: New Jersey (Menendez), Virginia (Kaine)\\nAs Geoffrey noted, the platinum-tier states listed here are the Democrats’ main problem. They have three senators up for reelection in states that Donald Trump carried by 8 (Ohio), 16 (Montana) and 39 (West Virginia!) percentage points in 2020. Each of those Democratic senators won reelection in 2018, of course, but that was a strong Democratic year, and there’s been further movement of white voters without college degrees — a key part of the electorate in these states — toward Republicans since then.',\n",
              " 'more likely than not they’ll be competitive again. And since we’re projecting a full six years out, I’m going to be a little bit more creative about considering long-shot opportunities in the bronze tier. Although the Senate races in Washington and Colorado received attention this year (Republicans spent a lot of money on both, only to lose by double digits), they wound up coming just as close in Oregon with a QAnon candidate as part of a comparatively strong year for the GOP in the Beaver State. Could a more mainstream GOP nominee have made it a race? Oregon is quite white, it has fewer people with college degrees than the “Portlandia” stereotype might make you assume, and Democratic incumbent Ron Wyden will be 79 years old in 2028 …\\nDemocratic pickup opportunities\\nPlatinum tier: None\\nGold tier: Wisconsin (Johnson), North Carolina (Budd)\\nSilver tier: Vance (Ohio)\\nBronze tier: Alaska (Murkowski), Florida (Rubio), Utah (Lee), Iowa (Grassley)\\nAgain, we’re mostly just rehashing this year’s map. Ron Johnson, who originally hadn’t planned on running in 2020, is another retirement threat in 2026 — and he barely won reelection anyway. In Ohio, Sherrod Brown could seek to return to the Senate if he loses in 2024 by challenging J.D. Vance. And 2028 is far enough from now that I wouldn’t want to rule out Democrats being competitive in states as far-flung as Utah, where independent Evan McMullin ran a fairly competitive race against Mike Lee this year.',\n",
              " '_id: 6529cfaff59ed61396db838c title: Ballot Measures: A Preview author: Walter Olson publish_date: 1697226504000.0 full_text: Walter Olson  Voters will go to the polls soon in states and municipalities to decide ballot issues of significance for individual liberty, limited government, and sound public administration. Some highlights (via Ballotpedia and Bolts):  If Ohio voters approve Issue 2\\xa0to legalize and regulate pot sales, more than half the U.S. population will live in states that have legalized recreational marijuana. Issue 1\\xa0in the same state would establish a\\xa0state constitutional right to “make and carry out one’s own reproductive decisions,” including decisions about abortion, contraception, fertility treatment, miscarriage care, and continuing pregnancy, while allowing the state to restrict abortion after fetal viability, except when “necessary to protect the pregnant patient’s life or health.”  Maine Question 3 would create a\\xa0state utility authorized to take over Maine’s privately owned electric utilities and transmission operations. Sen. Bernie Sanders (I‑VT) and the Sierra Club are among its backers on the left, but even some progressives have doubts and the utility workers’ union outright opposes the takeover. Ironically, one of the state’s two investor‐\\u200bowned utilities, serving areas in the north and east of the state, is itself owned by Calgary, Alberta’s municipal electric utility.  On public finance, Colorado Proposition HH is being promoted as a\\xa0reduction in property tax rates but is so drafted as to enable an end run around key provisions of the Colorado Taxpayer Bill of Rights (TABOR), enacted by voters in 1992, which has worked to limit the growth of government. Texas Proposition 3, a\\xa0constitutional amendment, would prohibit the legislature from enacting a\\xa0tax on wealth or on net worth in the future. It is one of more than a\\xa0dozen constitutional amendments on the Texas ballot with fiscal or tax implications. Maine Question 1 would require voter approval of many bond issuances above $1',\n",
              " \"ire voter approval of many bond issuances above $1 billion, and was advanced by opponents of Maine Question 3, the above‐\\u200bmentioned measure authorizing a\\xa0state takeover of electric utilities, which would presumably be funded by such bond issuances.  Ranked choice voting in municipal elections, an idea I’ve written about favorably, will be on the ballot in three mid‐\\u200bsized Michigan communities, Kalamazoo, East Lansing, and Royal Oak; the state would still have to give its approval. In Minnetonka, Minn., where voters approved RCV in 2020, opponents of the voting method have placed on the ballot a\\xa0measure that would reverse that decision. Earlier this year voters in Redondo Beach, Calif., and Burlington, Vt., approved RCV, the latest in a\\xa0streak of local wins for the method, which is also employed statewide in Maine and Alaska.  In Louisiana, which follows its own election schedule, voters will decide tomorrow whether to ban foundations and nonprofits from making private grants to election administrators, as about half the states have lately done. I’ve argued that there are legitimate reasons states might want to scrutinize and in some cases restrict such grants. A\\xa0new paper by Apoorva Lal and Daniel M. Thompson estimates that the receipt of a\\xa02020 grant had a\\xa0probable low‐\\u200bbut‐\\u200bpositive effect on turnout and on Democratic vote share, which works to confirm Republican political misgivings; at the same time they find (as has every other piece of serious research I\\xa0know) that the effects were likely too small\\xa0to have changed the outcome of that year’s presidential election.   url: https://www.cato.org/blog/ballot-measures-preview categories: ['news']\"]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "contents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmRD1vmCJ2Lk"
      },
      "outputs": [],
      "source": [
        "# Extract the metadata for each point returned by the similarity search\n",
        "# Each result (point) has a payload dictionary that includes metadata stored when uploading the vectors\n",
        "\n",
        "meta = [point.payload['metadata'] for point in text_hits]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfvQBxD5J5jH",
        "outputId": "f6e1f393-68eb-4315-d3f2-5add97fa938a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'source': 'Are The Democrats Screwed In The Senate After 2024?', 'row': 0},\n",
              " {'source': 'Are The Democrats Screwed In The Senate After 2024?', 'row': 0},\n",
              " {'source': 'Are The Democrats Screwed In The Senate After 2024?', 'row': 0},\n",
              " {'source': 'Are The Democrats Screwed In The Senate After 2024?', 'row': 0},\n",
              " {'source': 'Are The Democrats Screwed In The Senate After 2024?', 'row': 0},\n",
              " {'source': 'Are The Democrats Screwed In The Senate After 2024?', 'row': 0},\n",
              " {'source': 'Are The Democrats Screwed In The Senate After 2024?', 'row': 0},\n",
              " {'source': 'Are The Democrats Screwed In The Senate After 2024?', 'row': 0},\n",
              " {'source': 'Ballot Measures: A Preview', 'row': 2},\n",
              " {'source': 'Ballot Measures: A Preview', 'row': 2}]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "meta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4_gN9EMJ6JG",
        "outputId": "53bf97c2-a812-4c29-c058-13d519854fe8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "airly competitive race against Mike Lee this year. Even with an additional senator going into 2023, the 2024 map is still so bad for Democrats that keeping the Senate for years to come will be a fairly tough order. The party’s prospects might rest more upon limiting the damage in 2024 so that it has a chance to regain the Senate in 2026 or 2028. But a bad 2024 could make it very difficult for Democrats to regain the Senate before 2030 or 2032.\n",
            "That bleak picture may shape the next few years of political maneuvering. When Vox’s Dylan Matthews suggested on Twitter that liberal Justices Sonia Sotomayor (age 68) and Elena Kagan (age 62) should retire while Democrats have their Senate majority and be replaced by younger justices, it didn’t go over well. But it’s a perfectly rational suggestion if Democrats don’t feel like gambling with their judicial future. (Consider how consequential Ruth Bader Ginsburg’s decision not to retire has been for liberals.) Democrats have a narrow path to Senate control after 2024, but it’s narrow indeed, and one that might require the GOP continuing to nominate bad candidates — and a fair share of luck. url: https://fivethirtyeight.com/features/democrats-senate-chances-2024-and-beyond/ categories: ['news']\n",
            "###########\n",
            "_id: 63927168098523fa9d5ef047 title: Are The Democrats Screwed In The Senate After 2024? author: Nate Silver publish_date: 1670515535000.0 full_text: \n",
            "\n",
            "\n",
            "\n",
            "2028 Election\n",
            "Are The Democrats Screwed In The Senate After 2024?\n",
            "No, but the party faces an uphill battle.\n",
            "\n",
            "\n",
            "\n",
            "By Nate Silver\n",
            "\n",
            "\n",
            "Dec. 8, 2022, at 11:05 AM\t\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Samuel Corum / Getty Images\n",
            "###########\n",
            "which there’s typically some chance of retirement. Democrats also have a below-the-radar pickup opportunity in Alaska, where Mary Peltola was elected to a full term in the U.S. House10 last month by a 10-point margin after ranked-choice votes were tabulated. GOP incumbent Dan Sullivan has a mediocre approval rating and a Peltola-Sullivan race would potentially be competitive.\n",
            "Suppose, though, that Democrats win the presidency but lose the Senate in 2024. It’s really not as crazy as it sounds. If every state votes identically to how it did in the 2020 presidential election — and every Senate race follows the presidential vote — then Democrats would come out of 2024 with the presidency but only 48 Senate seats after losing West Virginia, Montana and Ohio. Could Democrats pick up two Senate seats from the GOP in the 2026 midterm while controlling the presidency? Unlikely — but then again, Democrats gaining Senate seats this year seemed unlikely and they did it.\n",
            "2028\n",
            "Republican pickup opportunities\n",
            "Platinum tier: None\n",
            "Gold tier: Nevada (Cortez Masto), Pennsylvania (Fetterman), Arizona (Kelly), Georgia (Warnock) \n",
            "Silver tier: New Hampshire (Hassan)\n",
            "Bronze tier: Oregon (Wyden)\n",
            "All right, now we’re literally coming full circle to consider the races that were just contested in last month’s midterm. So we’ll keep it pretty brief. Yes, Democrats have to feel pretty good about their wins in Nevada, Pennsylvania, Arizona and Georgia — especially given that the overall political environment wasn’t that great for Democrats this year. But they were narrow wins, and (with the possible exception of Nevada) they came against a mediocre set of GOP opponents. Maybe some of these races are toward the silver end of the gold tier, but more likely than not they’ll be competitive again.\n",
            "###########\n",
            "5 AM\t\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Samuel Corum / Getty Images I’m not that impressed by long-term projections of Democratic doom in the Senate. Mostly that’s because I’m not that impressed by long-term political projections in general. Political coalitions change; not many people would have had it on their bingo card that Democrats would obtain a Senate majority in 2020 by winning two runoffs in Georgia, and then would actually expand on that majority in 2022 following another runoff in Georgia despite their party controlling the White House.\n",
            "With that said, while I don’t think we can say very much about what politics will look like 10 or 20 years from now, a medium-term look-ahead is possible. Do Democrats have a reasonable hope of regaining a trifecta — control of the House, Senate and presidency — at any point in the near future (2024, 2026 or 2028)? And how long will they hold onto control of the Senate and the presidency, allowing them to appoint Supreme Court justices without Republican help?\n",
            "My colleague Geoffrey Skelley already took an initial look at the 2024 Senate map, which is bad for Democrats, but I wanted to dig slightly deeper and also consider 2026 and 2028. Like Geoffrey, I’ll be focused on the Senate, because that’s the weakest link in Democrats’ effort to win back the trifecta. Despite some disadvantages in the Electoral College, Democrats obviously have no trouble winning the presidency. And they nearly held onto the House this year despite losing the popular vote for the House. The current House map doesn’t have much — if any — of a Republican skew, and Democrats should be able to win back the House if the national political environment is reasonably good for them.\n",
            "###########\n",
            "e in these states — toward Republicans since then. I don’t want to focus too much on any one individual race, but it’s probably safe to assume that Joe Manchin has the toughest reelection campaign of all. Meanwhile, maybe Sherrod Brown can feel a bit more comfortable following Tim Ryan’s relatively good performance in Ohio this year, but Ryan did lose, and Brown may face a tougher opponent than Ryan did in J.D. Vance. Democrats also run the risk of retirements here; neither Manchin nor Jon Tester has officially yet announced they will seek reelection.\n",
            "Beyond the platinum tier, Democrats face some other risks. Kyrsten Sinema is likely to face a serious primary challenge. Democrats keep winning close races for Congress in Nevada but it’s a very purple state. Tammy Baldwin, Debbie Stabenow and Bob Casey won by fairly comfortable margins in 2018 and will likely be fine in the event of a decent-to-good Democratic year, but if 2024 turns into a good Republican year, they could be in trouble.\n",
            "Democratic pickup opportunities\n",
            "Platinum tier: None\n",
            "Gold tier: None\n",
            "Silver tier: Texas (Cruz), Florida (Scott)\n",
            "Bronze tier: None\n",
            "Conversely, it’s very slim pickings for Democrats. On paper, you’d think that Texas might be close — Ted Cruz won by less than 3 percentage points there in 2018 and Texas is more competitive than it once was — but the erosion of the Democratic vote in South Texas has prevented Texas from turning truly purple. And although Scott won by only 0.12 percentage points in 2018, Republicans did so well in Florida in 2020 and 2022 that I was tempted to demote his race all the way to the bronze tier. Plus, there’s a good chance that the GOP’s 2024 nominee will be either Florida Gov. Ron DeSantis or Florida resident Donald Trump, which could help drive Republican turnout.\n",
            "Beyond that, any other races look like an extreme stretch for Democrats. Maybe Josh Hawley in Missouri could be vulnerable in a 2018-type environment, but that’s less likely in a presidential year and Hawley’s approval rating isn’t that bad. Put him in the “honorable mention” tier, I guess.\n",
            "###########\n",
            " Put him in the “honorable mention” tier, I guess. Given all this, I’d imagine the modal outcome from 2024 is something like Republicans picking up about three Senate seats. There’s uncertainty around that; it’s surely within the realm of possibility that Democrats hold the Senate, but it’s also possible that Republicans could wind up with 54 or 55 seats. And of course, all of these races are correlated. If the GOP is doing well enough to win the presidency in 2024, they should have no trouble also winning the Senate.9\n",
            "2026\n",
            "Republican pickup opportunities \n",
            "Platinum tier: None\n",
            "Gold tier: Georgia (Ossoff), Michigan (Peters)\n",
            "Silver tier: New Hampshire (Shaheen)\n",
            "Bronze tier: Minnesota (Smith), Virginia (Warner)\n",
            "The 2026 map is more balanced. Democrats undoubtedly feel pretty good about how they’ve performed in Georgia and Michigan in the past two cycles, but Jon Ossoff and Gary Peters won by extremely narrow margins in 2020 and it would be a mistake to assume they’re safe. It’s not a particularly deep set of pickup opportunities for Republicans, though if Democrats retain the presidency in 2024, you’d expect Republicans to have good midterms in 2026, and New Hampshire and perhaps even Minnesota and Virginia could potentially be in play. \n",
            "Democratic pickup opportunities \n",
            "Platinum tier: None\n",
            "Gold tier: Maine (Collins), North Carolina (Tillis)\n",
            "Silver tier: Alaska (Sullivan)\n",
            "Bronze tier: Texas (Cornyn), Iowa (Ernst)\n",
            "Meanwhile, Democrats will try again in the two states that were most disappointing to them in 2020: Maine and North Carolina. Given all the focus on Georgia, I wonder if North Carolina hasn’t become underrated as a place where Democrats could gain ground in the future; the states are fairly similar demographically and it wouldn’t take that much of a shift for Democrats to go from narrowly losing races in North Carolina to narrowly winning them. Susan Collins will be 74 years old in 2026, meanwhile, an age at which there’s typically some chance of retirement.\n",
            "###########\n",
            "political environment is reasonably good for them. So let’s look at the 2024, 2026 and 2028 Senate maps (yes, 2028 features the same map as the midterm we just finished; I just can’t let go, I guess). We’ll classify races into bronze, silver, gold and platinum “tiers” in terms of how feasible they are as pickup opportunities. I’m deliberately using this goofy metallurgical theme as opposed to the categories FiveThirtyEight typically uses (e.g., “toss-up,” “lean Republican”) so you’ll recognize these as being back-of-the-envelope suppositions rather than any sort of official race ratings. \n",
            "In general, these ratings lean heavily on looking at how close a race was the last time it was contested, with some subjective adjustments for candidate quality. I’m also considering how the electoral environment has shifted within the state — Florida has gotten redder since Rick Scott was elected in 2018, for instance — although it is definitely not always safe to assume a state will continue trending in the same direction.\n",
            "2024\n",
            "Republican pickup opportunities\n",
            "Platinum tier: West Virginia (Manchin), Montana (Tester), Ohio (Brown), \n",
            "Gold tier: Arizona (Sinema), Nevada (Rosen)\n",
            "Silver tier: Wisconsin (Baldwin), Michigan (Stabenow), Pennsylvania (Casey)\n",
            "Bronze tier: New Jersey (Menendez), Virginia (Kaine)\n",
            "As Geoffrey noted, the platinum-tier states listed here are the Democrats’ main problem. They have three senators up for reelection in states that Donald Trump carried by 8 (Ohio), 16 (Montana) and 39 (West Virginia!) percentage points in 2020. Each of those Democratic senators won reelection in 2018, of course, but that was a strong Democratic year, and there’s been further movement of white voters without college degrees — a key part of the electorate in these states — toward Republicans since then.\n",
            "###########\n",
            "more likely than not they’ll be competitive again. And since we’re projecting a full six years out, I’m going to be a little bit more creative about considering long-shot opportunities in the bronze tier. Although the Senate races in Washington and Colorado received attention this year (Republicans spent a lot of money on both, only to lose by double digits), they wound up coming just as close in Oregon with a QAnon candidate as part of a comparatively strong year for the GOP in the Beaver State. Could a more mainstream GOP nominee have made it a race? Oregon is quite white, it has fewer people with college degrees than the “Portlandia” stereotype might make you assume, and Democratic incumbent Ron Wyden will be 79 years old in 2028 …\n",
            "Democratic pickup opportunities\n",
            "Platinum tier: None\n",
            "Gold tier: Wisconsin (Johnson), North Carolina (Budd)\n",
            "Silver tier: Vance (Ohio)\n",
            "Bronze tier: Alaska (Murkowski), Florida (Rubio), Utah (Lee), Iowa (Grassley)\n",
            "Again, we’re mostly just rehashing this year’s map. Ron Johnson, who originally hadn’t planned on running in 2020, is another retirement threat in 2026 — and he barely won reelection anyway. In Ohio, Sherrod Brown could seek to return to the Senate if he loses in 2024 by challenging J.D. Vance. And 2028 is far enough from now that I wouldn’t want to rule out Democrats being competitive in states as far-flung as Utah, where independent Evan McMullin ran a fairly competitive race against Mike Lee this year.\n",
            "###########\n",
            "_id: 6529cfaff59ed61396db838c title: Ballot Measures: A Preview author: Walter Olson publish_date: 1697226504000.0 full_text: Walter Olson  Voters will go to the polls soon in states and municipalities to decide ballot issues of significance for individual liberty, limited government, and sound public administration. Some highlights (via Ballotpedia and Bolts):  If Ohio voters approve Issue 2 to legalize and regulate pot sales, more than half the U.S. population will live in states that have legalized recreational marijuana. Issue 1 in the same state would establish a state constitutional right to “make and carry out one’s own reproductive decisions,” including decisions about abortion, contraception, fertility treatment, miscarriage care, and continuing pregnancy, while allowing the state to restrict abortion after fetal viability, except when “necessary to protect the pregnant patient’s life or health.”  Maine Question 3 would create a state utility authorized to take over Maine’s privately owned electric utilities and transmission operations. Sen. Bernie Sanders (I‑VT) and the Sierra Club are among its backers on the left, but even some progressives have doubts and the utility workers’ union outright opposes the takeover. Ironically, one of the state’s two investor‐​owned utilities, serving areas in the north and east of the state, is itself owned by Calgary, Alberta’s municipal electric utility.  On public finance, Colorado Proposition HH is being promoted as a reduction in property tax rates but is so drafted as to enable an end run around key provisions of the Colorado Taxpayer Bill of Rights (TABOR), enacted by voters in 1992, which has worked to limit the growth of government. Texas Proposition 3, a constitutional amendment, would prohibit the legislature from enacting a tax on wealth or on net worth in the future. It is one of more than a dozen constitutional amendments on the Texas ballot with fiscal or tax implications. Maine Question 1 would require voter approval of many bond issuances above $1\n",
            "###########\n",
            "ire voter approval of many bond issuances above $1 billion, and was advanced by opponents of Maine Question 3, the above‐​mentioned measure authorizing a state takeover of electric utilities, which would presumably be funded by such bond issuances.  Ranked choice voting in municipal elections, an idea I’ve written about favorably, will be on the ballot in three mid‐​sized Michigan communities, Kalamazoo, East Lansing, and Royal Oak; the state would still have to give its approval. In Minnetonka, Minn., where voters approved RCV in 2020, opponents of the voting method have placed on the ballot a measure that would reverse that decision. Earlier this year voters in Redondo Beach, Calif., and Burlington, Vt., approved RCV, the latest in a streak of local wins for the method, which is also employed statewide in Maine and Alaska.  In Louisiana, which follows its own election schedule, voters will decide tomorrow whether to ban foundations and nonprofits from making private grants to election administrators, as about half the states have lately done. I’ve argued that there are legitimate reasons states might want to scrutinize and in some cases restrict such grants. A new paper by Apoorva Lal and Daniel M. Thompson estimates that the receipt of a 2020 grant had a probable low‐​but‐​positive effect on turnout and on Democratic vote share, which works to confirm Republican political misgivings; at the same time they find (as has every other piece of serious research I know) that the effects were likely too small to have changed the outcome of that year’s presidential election.   url: https://www.cato.org/blog/ballot-measures-preview categories: ['news']\n",
            "###########\n"
          ]
        }
      ],
      "source": [
        "# Loop through each text chunk in the `contents` list\n",
        "# These are the top-matching results returned by the Qdrant similarity search\n",
        "for i in contents:\n",
        "    # Print the actual text content\n",
        "    print(i)\n",
        "\n",
        "    # Print a separator line to clearly distinguish between different chunks\n",
        "    print('###########')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHXedMrOKHFM"
      },
      "source": [
        "**5. Create a retriever function to extract relevant chunks from the documents.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EBXOh1oKHeh"
      },
      "outputs": [],
      "source": [
        "# Define a function to search the Qdrant vector database using a natural language query\n",
        "def query_qdrant(query, qdrant_client, limit=5):\n",
        "    # Step 1: Convert the query text into an embedding (vector representation)\n",
        "    # This embedding will be compared with stored vectors in the collection\n",
        "    query_em = get_text_embeddings(query)\n",
        "\n",
        "    # Step 2: Query the Qdrant collection using the embedding\n",
        "    # This finds the top `limit` most similar text chunks based on vector similarity\n",
        "    text_hits = qdrant_client.query_points(\n",
        "        collection_name=\"demo_collection\",  # The name of the Qdrant collection to search\n",
        "        query=query_em,                     # The embedding of the input query\n",
        "        limit=limit                         # Number of top results to return\n",
        "    ).points                                 # Extract the matching points (results)\n",
        "\n",
        "    # Step 3: Prepare the results in a clean format (text + metadata)\n",
        "    results = []\n",
        "    for point in text_hits:\n",
        "        results.append({\n",
        "            'content': point.payload['content'],    # The original text content\n",
        "            'metadata': point.payload['metadata']   # Associated metadata (e.g., title, row number)\n",
        "        })\n",
        "\n",
        "    # Return the list of results\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI7WPLTxKNqg",
        "outputId": "d0689fd2-a48d-4521-8441-f8d4cfe34ad6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'content': \"airly competitive race against Mike Lee this year. Even with an additional senator going into 2023, the 2024 map is still so bad for Democrats that keeping the Senate for years to come will be a fairly tough order. The party’s prospects might rest more upon limiting the damage in 2024 so that it has a chance to regain the Senate in 2026 or 2028. But a bad 2024 could make it very difficult for Democrats to regain the Senate before 2030 or 2032.\\nThat bleak picture may shape the next few years of political maneuvering. When Vox’s Dylan Matthews suggested on Twitter that liberal Justices Sonia Sotomayor (age 68) and Elena Kagan (age 62) should retire while Democrats have their Senate majority and be replaced by younger justices, it didn’t go over well. But it’s a perfectly rational suggestion if Democrats don’t feel like gambling with their judicial future. (Consider how consequential Ruth Bader Ginsburg’s decision not to retire has been for liberals.) Democrats have a narrow path to Senate control after 2024, but it’s narrow indeed, and one that might require the GOP continuing to nominate bad candidates — and a fair share of luck. url: https://fivethirtyeight.com/features/democrats-senate-chances-2024-and-beyond/ categories: ['news']\",\n",
              "  'metadata': {'source': 'Are The Democrats Screwed In The Senate After 2024?',\n",
              "   'row': 0}},\n",
              " {'content': '_id: 63927168098523fa9d5ef047 title: Are The Democrats Screwed In The Senate After 2024? author: Nate Silver publish_date: 1670515535000.0 full_text: \\n\\n\\n\\n2028 Election\\nAre The Democrats Screwed In The Senate After 2024?\\nNo, but the party faces an uphill battle.\\n\\n\\n\\nBy Nate Silver\\n\\n\\nDec. 8, 2022, at 11:05 AM\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSamuel Corum / Getty Images',\n",
              "  'metadata': {'source': 'Are The Democrats Screwed In The Senate After 2024?',\n",
              "   'row': 0}},\n",
              " {'content': 'which there’s typically some chance of retirement. Democrats also have a below-the-radar pickup opportunity in Alaska, where Mary Peltola was elected to a full term in the U.S. House10 last month by a 10-point margin after ranked-choice votes were tabulated. GOP incumbent Dan Sullivan has a mediocre approval rating and a Peltola-Sullivan race would potentially be competitive.\\nSuppose, though, that Democrats win the presidency but lose the Senate in 2024. It’s really not as crazy as it sounds. If every state votes identically to how it did in the 2020 presidential election — and every Senate race follows the presidential vote — then Democrats would come out of 2024 with the presidency but only 48 Senate seats after losing West Virginia, Montana and Ohio. Could Democrats pick up two Senate seats from the GOP in the 2026 midterm while controlling the presidency? Unlikely — but then again, Democrats gaining Senate seats this year seemed unlikely and they did it.\\n2028\\nRepublican pickup opportunities\\nPlatinum tier: None\\nGold tier: Nevada (Cortez Masto), Pennsylvania (Fetterman), Arizona (Kelly), Georgia (Warnock) \\nSilver tier: New Hampshire (Hassan)\\nBronze tier: Oregon (Wyden)\\nAll right, now we’re literally coming full circle to consider the races that were just contested in last month’s midterm. So we’ll keep it pretty brief. Yes, Democrats have to feel pretty good about their wins in Nevada, Pennsylvania, Arizona and Georgia — especially given that the overall political environment wasn’t that great for Democrats this year. But they were narrow wins, and (with the possible exception of Nevada) they came against a mediocre set of GOP opponents. Maybe some of these races are toward the silver end of the gold tier, but more likely than not they’ll be competitive again.',\n",
              "  'metadata': {'source': 'Are The Democrats Screwed In The Senate After 2024?',\n",
              "   'row': 0}},\n",
              " {'content': '5 AM\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSamuel Corum / Getty Images I’m not that impressed by long-term projections of Democratic doom in the Senate. Mostly that’s because I’m not that impressed by long-term political projections in general. Political coalitions change; not many people would have had it on their bingo card that Democrats would obtain a Senate majority in 2020 by winning two runoffs in Georgia, and then would actually expand on that majority in 2022 following another runoff in Georgia despite their party controlling the White House.\\nWith that said, while I don’t think we can say very much about what politics will look like 10 or 20 years from now, a medium-term look-ahead is possible. Do Democrats have a reasonable hope of regaining a trifecta — control of the House, Senate and presidency — at any point in the near future (2024, 2026 or 2028)? And how long will they hold onto control of the Senate and the presidency, allowing them to appoint Supreme Court justices without Republican help?\\nMy colleague Geoffrey Skelley already took an initial look at the 2024 Senate map, which is bad for Democrats, but I wanted to dig slightly deeper and also consider 2026 and 2028. Like Geoffrey, I’ll be focused on the Senate, because that’s the weakest link in Democrats’ effort to win back the trifecta. Despite some disadvantages in the Electoral College, Democrats obviously have no trouble winning the presidency. And they nearly held onto the House this year despite losing the popular vote for the House. The current House map doesn’t have much — if any — of a Republican skew, and Democrats should be able to win back the House if the national political environment is reasonably good for them.',\n",
              "  'metadata': {'source': 'Are The Democrats Screwed In The Senate After 2024?',\n",
              "   'row': 0}},\n",
              " {'content': 'e in these states — toward Republicans since then. I don’t want to focus too much on any one individual race, but it’s probably safe to assume that Joe Manchin has the toughest reelection campaign of all. Meanwhile, maybe Sherrod Brown can feel a bit more comfortable following Tim Ryan’s relatively good performance in Ohio this year, but Ryan did lose, and Brown may face a tougher opponent than Ryan did in J.D. Vance. Democrats also run the risk of retirements here; neither Manchin nor Jon Tester has officially yet announced they will seek reelection.\\nBeyond the platinum tier, Democrats face some other risks. Kyrsten Sinema is likely to face a serious primary challenge. Democrats keep winning close races for Congress in Nevada but it’s a very purple state. Tammy Baldwin, Debbie Stabenow and Bob Casey won by fairly comfortable margins in 2018 and will likely be fine in the event of a decent-to-good Democratic year, but if 2024 turns into a good Republican year, they could be in trouble.\\nDemocratic pickup opportunities\\nPlatinum tier: None\\nGold tier: None\\nSilver tier: Texas (Cruz), Florida (Scott)\\nBronze tier: None\\nConversely, it’s very slim pickings for Democrats. On paper, you’d think that Texas might be close — Ted Cruz won by less than 3 percentage points there in 2018 and Texas is more competitive than it once was — but the erosion of the Democratic vote in South Texas has prevented Texas from turning truly purple. And although Scott won by only 0.12 percentage points in 2018, Republicans did so well in Florida in 2020 and 2022 that I was tempted to demote his race all the way to the bronze tier. Plus, there’s a good chance that the GOP’s 2024 nominee will be either Florida Gov. Ron DeSantis or Florida resident Donald Trump, which could help drive Republican turnout.\\nBeyond that, any other races look like an extreme stretch for Democrats. Maybe Josh Hawley in Missouri could be vulnerable in a 2018-type environment, but that’s less likely in a presidential year and Hawley’s approval rating isn’t that bad. Put him in the “honorable mention” tier, I guess.',\n",
              "  'metadata': {'source': 'Are The Democrats Screwed In The Senate After 2024?',\n",
              "   'row': 0}}]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_qdrant(query, client)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBpR6ENvKR8v"
      },
      "source": [
        "**6. Now, let's integrate everything by combining our Retrieval functiom with the Language Model to complete our RAG (Retrieval-Augmented Generation) pipeline.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SaDz2BY-KOa8"
      },
      "outputs": [],
      "source": [
        "# Define a function that uses a language model to generate an answer based on a user's query\n",
        "def generate_answer(query):\n",
        "    # Build the prompt that will be sent to the LLM\n",
        "    # The prompt includes:\n",
        "    # - Instructions to clean and format the answer\n",
        "    # - The user's original query\n",
        "    # - The context retrieved from Qdrant (via semantic search)\n",
        "    prompt = f\"\"\"\n",
        "    Based on the following query from a user, please generate a small answer\n",
        "    focusing on the original query and the response given. The answer should be paragraphs.\n",
        "    Remove the special characters and (/n), make the output clean and long.\n",
        "    Please cite source for each part as [1][2].\n",
        "    Just start with the answer, no need to give any salutations.\n",
        "\n",
        "    ###########\n",
        "    query:\n",
        "    \"{query}\"\n",
        "\n",
        "    ########\n",
        "\n",
        "    context:\n",
        "    \"{query_qdrant(query, client)}\"\n",
        "    #####\n",
        "\n",
        "    Return in Markdown format.\n",
        "    \"\"\"\n",
        "\n",
        "    # Send the prompt to the LLM using streaming mode\n",
        "    # This allows the response to be received in real-time, piece by piece\n",
        "    stream = open_router_client.chat.completions.create(\n",
        "        model=\"qwen/qwen3-8b:free\",  # Model to use (can be any OpenAI-compatible model)\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            },\n",
        "        ],\n",
        "        stream=True,  # Enable streaming so we get partial output as it generates\n",
        "    )\n",
        "\n",
        "    # Initialize a variable to hold the full response\n",
        "    output_text = \"\"\n",
        "\n",
        "    # Iterate through the streaming response chunks\n",
        "    for chunk in stream:\n",
        "        if chunk.choices[0].delta.content is not None:\n",
        "            content = chunk.choices[0].delta.content\n",
        "            output_text += content  # Append new content to the full output\n",
        "            print(content, end=\"\")  # Print each chunk live as it's received\n",
        "\n",
        "    # Return both the final answer and the context used (for reference or display)\n",
        "    return output_text, query_qdrant(query, client)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "qV4eIY9-KeT5",
        "outputId": "86b7abcc-632c-471f-aee5-42b4a15812a7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "      pre {\n",
              "          white-space: pre-wrap;  /* Enable word-wrapping in code/output blocks */\n",
              "      }\n",
              "    </style>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Democrats face significant challenges in maintaining Senate control after 2024, as the current political map is heavily unfavorable for their interests. The 2024 Senate race is described as exceptionally difficult for the party, with even an additional senator in 2023 not enough to secure long-term dominance. Democrats’ prospects rely on minimizing losses in 2024 to create a viable path for regaining the Senate in 2026 or 2028. However, a poor performance in 2024 could severely hinder their ability to recapture majority control before 2030 or 2032. This precarious situation influences strategic political decisions, including discussions about judicial appointments and retirement timelines for Supreme Court justices, as highlighted by Nate Silver’s analysis [1].  \n",
            "\n",
            "The 2024 election outcomes will heavily determine the Democrats’ Senate outlook. If Democrats win the presidency but lose the Senate, it would not be an unprecedented scenario. However, the party’s ability to regain Senate seats in subsequent midterms, such as 2026 or 2028, is uncertain. Key races in Nevada, Pennsylvania, Arizona, and Georgia are considered critical, as narrow victories in these states could shape the party’s trajectory. Despite these wins, the political environment in 2024 remains challenging, and the Democratic candidates faced mediocre opposition. The success of these races will depend on both national trends and localized factors, such as voter turnout and candidate strength [1].  \n",
            "\n",
            "Democrats also face risks of losing Senate seats if they fail to secure a strong position in 2024. High-profile races, such as those involving Joe Manchin and Sherrod Brown, highlight vulnerabilities. Manchin’s reelection is seen as particularly difficult, while Brown’s prospects depend on the performance of his opponent, J.D. Vance. Additionally, potential retirements, such as those from Kyrsten Sinema and Jon Tester, add uncertainty. The party must also navigate primary challenges, as seen in Nevada, where narrow victories suggest fragile support. These factors underscore the need for strategic planning to retain Senate control [1].  \n",
            "\n",
            "Looking ahead to 2028, Democrats face limited opportunities to gain Senate seats, with only a few states classified as competitive. Races in Texas (Ted Cruz) and Florida (Ron DeSantis) are considered potential targets, though challenges persist due to shifting voter bases and strong Republican turnout. The GOP’s dominance in states like Florida and Texas complicates Democratic prospects, as does the likelihood of a prominent Republican presidential candidate, such as Donald Trump, boosting turnout. These dynamics make it unlikely for Democrats to achieve a significant majority in the near future without substantial shifts in political alignment [1].  \n",
            "\n",
            "The Senate’s control is also critical for Democratic judicial strategy, as the party aims to appoint justices without Republican cooperation. The 2024 election’s outcome will determine whether Democrats can maintain their ability to shape the Supreme Court. Strategic considerations, including retirements and judicial appointments, reflect the urgency of securing Senate control. While long-term political forecasts are uncertain, the immediate challenges hinge on navigating a difficult 2024 map, mitigating losses, and leveraging narrow victories in key states [1]."
          ]
        }
      ],
      "source": [
        "response,sources = generate_answer(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "R08hGy5TKvN-",
        "outputId": "39dc11f3-a7c3-465d-9e1c-33c41051e14a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "      pre {\n",
              "          white-space: pre-wrap;  /* Enable word-wrapping in code/output blocks */\n",
              "      }\n",
              "    </style>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<p>The Democrats face significant challenges in maintaining Senate control after 2024, as the current political map is heavily unfavorable for their interests. The 2024 Senate race is described as exceptionally difficult for the party, with even an additional senator in 2023 not enough to secure long-term dominance. Democrats’ prospects rely on minimizing losses in 2024 to create a viable path for regaining the Senate in 2026 or 2028. However, a poor performance in 2024 could severely hinder their ability to recapture majority control before 2030 or 2032. This precarious situation influences strategic political decisions, including discussions about judicial appointments and retirement timelines for Supreme Court justices, as highlighted by Nate Silver’s analysis [1].  </p>\n",
              "<p>The 2024 election outcomes will heavily determine the Democrats’ Senate outlook. If Democrats win the presidency but lose the Senate, it would not be an unprecedented scenario. However, the party’s ability to regain Senate seats in subsequent midterms, such as 2026 or 2028, is uncertain. Key races in Nevada, Pennsylvania, Arizona, and Georgia are considered critical, as narrow victories in these states could shape the party’s trajectory. Despite these wins, the political environment in 2024 remains challenging, and the Democratic candidates faced mediocre opposition. The success of these races will depend on both national trends and localized factors, such as voter turnout and candidate strength [1].  </p>\n",
              "<p>Democrats also face risks of losing Senate seats if they fail to secure a strong position in 2024. High-profile races, such as those involving Joe Manchin and Sherrod Brown, highlight vulnerabilities. Manchin’s reelection is seen as particularly difficult, while Brown’s prospects depend on the performance of his opponent, J.D. Vance. Additionally, potential retirements, such as those from Kyrsten Sinema and Jon Tester, add uncertainty. The party must also navigate primary challenges, as seen in Nevada, where narrow victories suggest fragile support. These factors underscore the need for strategic planning to retain Senate control [1].  </p>\n",
              "<p>Looking ahead to 2028, Democrats face limited opportunities to gain Senate seats, with only a few states classified as competitive. Races in Texas (Ted Cruz) and Florida (Ron DeSantis) are considered potential targets, though challenges persist due to shifting voter bases and strong Republican turnout. The GOP’s dominance in states like Florida and Texas complicates Democratic prospects, as does the likelihood of a prominent Republican presidential candidate, such as Donald Trump, boosting turnout. These dynamics make it unlikely for Democrats to achieve a significant majority in the near future without substantial shifts in political alignment [1].  </p>\n",
              "<p>The Senate’s control is also critical for Democratic judicial strategy, as the party aims to appoint justices without Republican cooperation. The 2024 election’s outcome will determine whether Democrats can maintain their ability to shape the Supreme Court. Strategic considerations, including retirements and judicial appointments, reflect the urgency of securing Senate control. While long-term political forecasts are uncertain, the immediate challenges hinge on navigating a difficult 2024 map, mitigating losses, and leveraging narrow victories in key states [1].</p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#for markdown layout\n",
        "render_markdown(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMAcLhWBKyjB"
      },
      "source": [
        "## Time to Build a functional Gradio interface to interact with the RAG system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "DzlrpSQDKzir",
        "outputId": "6965fc7a-6175-4575-c6f9-fa67c780b3b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "      pre {\n",
              "          white-space: pre-wrap;  /* Enable word-wrapping in code/output blocks */\n",
              "      }\n",
              "    </style>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6UjqV9lLFs-"
      },
      "source": [
        "**1. Redefine our RAG function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7m95aVNHK7O_",
        "outputId": "4701851e-7d7b-482a-ddd9-1ecaf48907fe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "      pre {\n",
              "          white-space: pre-wrap;  /* Enable word-wrapping in code/output blocks */\n",
              "      }\n",
              "    </style>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Import OpenAI-compatible library (used here with OpenRouter)\n",
        "import openai\n",
        "\n",
        "# Define a function to generate a streamed answer to a user's query using an LLM\n",
        "# This version includes error handling and uses Python's `yield` to stream results back as they're generated\n",
        "def generate_answer(query):\n",
        "    # Step 1: Try to get relevant context from Qdrant (vector search)\n",
        "    try:\n",
        "        sources = query_qdrant(query, client)\n",
        "    except Exception as e:\n",
        "        # If something goes wrong (e.g., Qdrant is not running), return a fallback message\n",
        "        sources = [{\"error\": f\"Error retrieving sources: {str(e)}\"}]\n",
        "\n",
        "    # Step 2: Prepare the prompt for the language model\n",
        "    # Includes the user's question and the context retrieved from the vector database\n",
        "    prompt = f\"\"\"\n",
        "    Based on the following query from a user, please generate a small answer\n",
        "    focusing on the original query and the response given. The answer should be paragraphs.\n",
        "    Remove special characters and (/n); make the output clean and long.\n",
        "    Please cite source for each part as [1][2]. Just start with the answer — no salutations.\n",
        "\n",
        "    ###########\n",
        "    query:\n",
        "    \"{query}\"\n",
        "\n",
        "    ########\n",
        "\n",
        "    context:\n",
        "    \"{sources}\"\n",
        "    #####\n",
        "\n",
        "    Return in Markdown format.\n",
        "    \"\"\"\n",
        "\n",
        "    # Step 3: Send the prompt to the OpenRouter-compatible LLM (Qwen model)\n",
        "    stream = open_router_client.chat.completions.create(\n",
        "        model=\"qwen/qwen3-8b:free\",  # A free-to-use large language model hosted on OpenRouter\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            },\n",
        "        ],\n",
        "        stream=True,  # Enable streaming response\n",
        "    )\n",
        "\n",
        "    # Step 4: Stream and yield the generated content chunk by chunk\n",
        "    full_response = \"\"\n",
        "    for chunk in stream:\n",
        "        if chunk.choices[0].delta.content is not None:\n",
        "            content = chunk.choices[0].delta.content\n",
        "            full_response += content\n",
        "\n",
        "            # Yield lets us return partial results as they're received (for real-time feedback)\n",
        "            yield full_response\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhA94_wtLP0Y"
      },
      "source": [
        "**2. Create a Demo Interface**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "qBKeIxdoLRKZ",
        "outputId": "0bb5f7da-52a9-4736-e63b-f6f0c2fdbc15"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "      pre {\n",
              "          white-space: pre-wrap;  /* Enable word-wrapping in code/output blocks */\n",
              "      }\n",
              "    </style>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://b7f9733d761220a24f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://b7f9733d761220a24f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://b7f9733d761220a24f.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define example inputs for the UI — users can click these to try predefined queries\n",
        "examples = [\n",
        "    [\"Democrats in Senate\"],\n",
        "    [\"Climate Change Challenges in Europe\"],\n",
        "    [\"Philosophy in the world of Minimalism\"],\n",
        "    [\"Hate Speech vs Freedom of Speech\"],\n",
        "    [\"Articles by Noam Chomsky on US Politics\"],\n",
        "    [\"The importance of values and reflection\"]\n",
        "]\n",
        "\n",
        "# Set up the Gradio interface\n",
        "# - fn: the function to call when user enters input (must be a generator if using yield)\n",
        "# - title: the name shown at the top of the web app\n",
        "# - inputs: defines the input component (in this case, a text box)\n",
        "# - outputs: defines what kind of output to display (Textbox with 3 lines labeled \"Response\")\n",
        "# - examples: preloaded example queries for users to click and run\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=generate_answer,  # The function that will process user input\n",
        "    title=\"The Truth Serum\",  # Title for the web app\n",
        "    inputs=\"text\",  # Single text input from the user\n",
        "    outputs=gr.components.Textbox(lines=3, label=\"Response\"),  # Output display\n",
        "    examples=examples,  # List of sample queries for users to try\n",
        "    live=False,  # Optional: set to True if you want real-time feedback as user types\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "# - share=True gives you a public link (useful in Colab or for sharing with others)\n",
        "# - debug=True enables logging for error tracking\n",
        "demo.launch(share=True, debug=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQBN4NTKMgKv"
      },
      "source": [
        "**3. Create a Demo Interface with Sources**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        },
        "id": "cMiNSarNLtzg",
        "outputId": "32ee5668-f403-44bb-9eff-0452a805b373"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "      pre {\n",
              "          white-space: pre-wrap;  /* Enable word-wrapping in code/output blocks */\n",
              "      }\n",
              "    </style>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://f53afd903f889cb305.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://f53afd903f889cb305.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://f53afd903f889cb305.gradio.live\n"
          ]
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "def generate_answer(query):\n",
        "    # First, get the sources\n",
        "    try:\n",
        "        sources = query_qdrant(query, client)\n",
        "    except Exception as e:\n",
        "        sources = [{\"error\": f\"Error retrieving sources: {str(e)}\"}]\n",
        "\n",
        "    # Convert the sources list to a string for the prompt\n",
        "    #sources_str = \"\\n\".join([f\"Source {i+1}: {source['content']}\" for i, source in enumerate(sources)])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Based on the following query from a user, please generate a small answer\n",
        "    focusing on the original query and the response given. The answer should be paragraphs\n",
        "    remove the special characters and (/n ), make the output clean and long. Please cite source for each part as [1][2]\n",
        "    Just start with the answer, no need to give any salutations\n",
        "\n",
        "    ###########\n",
        "    query:\n",
        "    \"{query}\"\n",
        "\n",
        "    ########\n",
        "\n",
        "    context:\n",
        "    \"{sources}\"\n",
        "    #####\n",
        "\n",
        "    Return in Markdown format.\n",
        "    \"\"\"\n",
        "\n",
        "    # Send the prompt to the OpenRouter-compatible LLM (Qwen model)\n",
        "    stream = open_router_client.chat.completions.create(\n",
        "        model=\"qwen/qwen3-8b:free\",  # A free-to-use large language model hosted on OpenRouter\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            },\n",
        "        ],\n",
        "        stream=True,  # Enable streaming response\n",
        "    )\n",
        "    # Convert sources to a proper JSON string for the JSON component\n",
        "    sources_json = json.dumps(sources)\n",
        "\n",
        "    # For Gradio streaming with multiple outputs\n",
        "    full_response = \"\"\n",
        "    for chunk in stream:\n",
        "        if chunk.choices[0].delta.content is not None:\n",
        "            content = chunk.choices[0].delta.content\n",
        "            full_response += content\n",
        "            # Return both the accumulated response and the sources as JSON string\n",
        "            yield full_response, sources_json\n",
        "\n",
        "    # In case the stream is empty, yield one final time\n",
        "    if not full_response:\n",
        "        yield \"No response generated\", sources_json\n",
        "\n",
        "examples = [\n",
        "    [\"Democrats in Senate\"],\n",
        "    [\"Climate Change Challenges in Europe\"],\n",
        "    [\"Philosophy in the world of Minimalism\"],\n",
        "    [\"Hate Speech vs Freedom of Speech\"],\n",
        "    [\"Articles by Noam Chomsky on US Politics\"],\n",
        "    [\"The importance of values and reflection\"]\n",
        "]\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=generate_answer,\n",
        "    title=\"The Truth Serum\",\n",
        "    inputs=\"text\",\n",
        "    outputs=[\n",
        "        gr.components.Textbox(lines=8, label=\"Response\"),\n",
        "        gr.components.JSON(label=\"Sources\")\n",
        "    ],\n",
        "    examples=examples\n",
        ")\n",
        "\n",
        "demo.queue()\n",
        "demo.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NGxa_zvMFE2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "015ff099ca4b477b9fc4e484db77f330": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91e0d2d163a94e6e817ec2776bde8a7a",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a87406edcb354e798e81784b49e16f15",
            "value": 231508
          }
        },
        "025a8a6df2bd40b59bf076dd15d1cef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55885ef6e8f74b1bbf73f08a8d156abb",
            "placeholder": "​",
            "style": "IPY_MODEL_46570d5e1c244a31b401d2424c3010f5",
            "value": " 547M/547M [00:02&lt;00:00, 243MB/s]"
          }
        },
        "072637dcdb144cbdb3d02146bb62a6b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0da3450aef084297a87ca27b5f3b7455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e305e64e68c4cb8bdbb5b220b4da828",
              "IPY_MODEL_8e80335c0d474855b5654be48555bc05",
              "IPY_MODEL_8d717204cab04451ad1226d800503169"
            ],
            "layout": "IPY_MODEL_9b824fb8720d46d59adbf4c5d9ed445a"
          }
        },
        "0e305e64e68c4cb8bdbb5b220b4da828": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_642e221cb1fc4b04a76a327a1ef8d926",
            "placeholder": "​",
            "style": "IPY_MODEL_32db8a4aa90a449093b1a455ba5200da",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0e84768499c74d809a1a4bc89df8493f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "182b5d77998c43cda26c8bf442881780": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d6d7018d3744de2ac21f426030ce2e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f4c8cd8e700490791def2a9b434ecf6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22a7901cd876417089869865201bfc56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28ed36d1e5de4aac882fe4cf3c9dccc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d6d7018d3744de2ac21f426030ce2e6",
            "placeholder": "​",
            "style": "IPY_MODEL_d7da4d7caa464789a74d29611c19ab52",
            "value": " 695/695 [00:00&lt;00:00, 10.1kB/s]"
          }
        },
        "32db8a4aa90a449093b1a455ba5200da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "383b9bdbf235450ba24127329f4c3055": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "398b3a390a3c4f7b8d80d740053c5d0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45831dc836b54ab38892d1f134feb712": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46570d5e1c244a31b401d2424c3010f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "484ee07ba9c84306be862601b18bd4f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49530a8c740f481fbaf1d7d731c135d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bda983f76ca406b9e7aaaf17ddfcd2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e5149ea6c3e4b679a99cbaeaa204198": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f75d233562142608e848df70a578b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f922a9a5d2de4a918e06cfd7e6f463e2",
            "max": 103563,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b54ea46ea2a6463b9f51db677bd19455",
            "value": 103563
          }
        },
        "5071019c68f8495fb419a4526eb49fdd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51eefd0687fa48199eb82e378b0a04f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "526b8e549ae84121b694b188cc67dd6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_872405ea1c21471a8ce7d616f0d60d4b",
            "placeholder": "​",
            "style": "IPY_MODEL_b69105d0c1144b92ad4e0fa1311fa376",
            "value": "model.safetensors: 100%"
          }
        },
        "549ceb46221747b785286ed66217e734": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5071019c68f8495fb419a4526eb49fdd",
            "max": 695,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8eb1cef2dd53435a9afe03dc87d473d2",
            "value": 695
          }
        },
        "5560c904fb504690aa66860f3ea5e299": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55885ef6e8f74b1bbf73f08a8d156abb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56812bfabd2c42ac85afc79a7fbd6b19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b9c5f7cfefc4199b6bcb9ab342843f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_484ee07ba9c84306be862601b18bd4f3",
            "max": 2064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51eefd0687fa48199eb82e378b0a04f6",
            "value": 2064
          }
        },
        "5e328da6d36b4fb3b3cc0bd4c2740482": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66940d4565b744a08c0d03ab036e9c31",
            "placeholder": "​",
            "style": "IPY_MODEL_b6da49162669458195d988c816b05283",
            "value": "config.json: 100%"
          }
        },
        "642e221cb1fc4b04a76a327a1ef8d926": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64ebfd52cd5c4a9eb928368c4fe782c7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "667e57c917654d0995c1814d3ef9859b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66940d4565b744a08c0d03ab036e9c31": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67ba4db660e34ac296a3cd782b785d89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "68e78e9e9d174466a17f53cc66896c4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d0d1c53599b45279453ccaf390e08e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e1e4ddf68994b30bbb3bd1976a2590e",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a888c823fc44e1fa989cf55517ae28b",
            "value": 711396
          }
        },
        "6e5b29d9a6ec4259b573829517d7966c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73f72dcae0424e56b9a9fbac09eb099b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76fd05fbe15e4d83b0410e2e081b5824": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb72465fcb7443fda7b9a13dbe161fdd",
            "placeholder": "​",
            "style": "IPY_MODEL_0e84768499c74d809a1a4bc89df8493f",
            "value": "tokenizer.json: 100%"
          }
        },
        "7a027b73a9c34f0d8b739f9ddf60e59e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a888c823fc44e1fa989cf55517ae28b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e1e4ddf68994b30bbb3bd1976a2590e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80bc061644ee4b5a807070c5eef483d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e328da6d36b4fb3b3cc0bd4c2740482",
              "IPY_MODEL_5b9c5f7cfefc4199b6bcb9ab342843f2",
              "IPY_MODEL_8e647bfd40304cccb6da9101673260ce"
            ],
            "layout": "IPY_MODEL_1f4c8cd8e700490791def2a9b434ecf6"
          }
        },
        "872405ea1c21471a8ce7d616f0d60d4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c6f329aa3584359b6f1ed053b4eded6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d717204cab04451ad1226d800503169": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbad5107b38a4303bbe014e791c520fd",
            "placeholder": "​",
            "style": "IPY_MODEL_9b77a6bfb1644c4e9abf47f729aa185e",
            "value": " 1.19k/1.19k [00:00&lt;00:00, 54.6kB/s]"
          }
        },
        "8e647bfd40304cccb6da9101673260ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64ebfd52cd5c4a9eb928368c4fe782c7",
            "placeholder": "​",
            "style": "IPY_MODEL_f82260623c3b452fbd4f25b4eea122c0",
            "value": " 2.06k/2.06k [00:00&lt;00:00, 35.5kB/s]"
          }
        },
        "8e80335c0d474855b5654be48555bc05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91a98acbe6714b909fa660244da7d35f",
            "max": 1191,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a027b73a9c34f0d8b739f9ddf60e59e",
            "value": 1191
          }
        },
        "8eb1cef2dd53435a9afe03dc87d473d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f9a66713b344c27b6af1d017966bce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f958abd6a3244a1ea0648d49406bc229",
            "placeholder": "​",
            "style": "IPY_MODEL_4bda983f76ca406b9e7aaaf17ddfcd2c",
            "value": " 104k/104k [00:00&lt;00:00, 4.53MB/s]"
          }
        },
        "9000a470f62c46e383414ea4d73a9edf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91a98acbe6714b909fa660244da7d35f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91e0d2d163a94e6e817ec2776bde8a7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93aada13a77e49638b4839c629c213d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_526b8e549ae84121b694b188cc67dd6c",
              "IPY_MODEL_b665d5ea3b2d4e3c91753189b7825f30",
              "IPY_MODEL_025a8a6df2bd40b59bf076dd15d1cef0"
            ],
            "layout": "IPY_MODEL_9000a470f62c46e383414ea4d73a9edf"
          }
        },
        "9b77a6bfb1644c4e9abf47f729aa185e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b824fb8720d46d59adbf4c5d9ed445a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4487c00ed054ad9b326449607b73b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c6f329aa3584359b6f1ed053b4eded6",
            "placeholder": "​",
            "style": "IPY_MODEL_67ba4db660e34ac296a3cd782b785d89",
            "value": "vocab.txt: 100%"
          }
        },
        "a87406edcb354e798e81784b49e16f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aaa66d0338584cf68402e9170ede6a43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd29a5d1d5ed4bf8b4f09da5ec762cd4",
              "IPY_MODEL_549ceb46221747b785286ed66217e734",
              "IPY_MODEL_28ed36d1e5de4aac882fe4cf3c9dccc7"
            ],
            "layout": "IPY_MODEL_45831dc836b54ab38892d1f134feb712"
          }
        },
        "ad7b87183aa54bb69669ba6d77b77f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5560c904fb504690aa66860f3ea5e299",
            "placeholder": "​",
            "style": "IPY_MODEL_caec68596530403c8dc4beeb69b80165",
            "value": " 232k/232k [00:00&lt;00:00, 2.90MB/s]"
          }
        },
        "b0974d11f54f40528947ea92cfb5e467": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22a7901cd876417089869865201bfc56",
            "placeholder": "​",
            "style": "IPY_MODEL_072637dcdb144cbdb3d02146bb62a6b7",
            "value": " 1.96k/1.96k [00:00&lt;00:00, 32.2kB/s]"
          }
        },
        "b54ea46ea2a6463b9f51db677bd19455": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b665d5ea3b2d4e3c91753189b7825f30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56812bfabd2c42ac85afc79a7fbd6b19",
            "max": 546938168,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea1d77a9fb504379979403c8d00fb315",
            "value": 546938168
          }
        },
        "b69105d0c1144b92ad4e0fa1311fa376": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6da49162669458195d988c816b05283": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b79cf41efaba4123bf69674d31a46428": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba9625d4c9c943cfa487f001f44759e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb14933f64a747229b490f6915fa3107": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da4db2195578448ea94bb71618aac853",
              "IPY_MODEL_eb7c4edeac6843dfb8bb2d0e6412d376",
              "IPY_MODEL_b0974d11f54f40528947ea92cfb5e467"
            ],
            "layout": "IPY_MODEL_4e5149ea6c3e4b679a99cbaeaa204198"
          }
        },
        "bbad5107b38a4303bbe014e791c520fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc8f5eaf8e724078b785aec8620303cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3c0583f9f314adcbc3d1e6c0d9e412b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b79cf41efaba4123bf69674d31a46428",
            "placeholder": "​",
            "style": "IPY_MODEL_f19f6758c2854065a696e010d8a24f59",
            "value": " 711k/711k [00:00&lt;00:00, 1.46MB/s]"
          }
        },
        "c3c4b933e7be4e22bbf4450dd982eeb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_398b3a390a3c4f7b8d80d740053c5d0d",
            "placeholder": "​",
            "style": "IPY_MODEL_6e5b29d9a6ec4259b573829517d7966c",
            "value": "modeling_hf_nomic_bert.py: 100%"
          }
        },
        "caec68596530403c8dc4beeb69b80165": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb72465fcb7443fda7b9a13dbe161fdd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd29a5d1d5ed4bf8b4f09da5ec762cd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73f72dcae0424e56b9a9fbac09eb099b",
            "placeholder": "​",
            "style": "IPY_MODEL_49530a8c740f481fbaf1d7d731c135d0",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "d7da4d7caa464789a74d29611c19ab52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da4db2195578448ea94bb71618aac853": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba9625d4c9c943cfa487f001f44759e8",
            "placeholder": "​",
            "style": "IPY_MODEL_bc8f5eaf8e724078b785aec8620303cc",
            "value": "configuration_hf_nomic_bert.py: 100%"
          }
        },
        "e9e35cbefa184a3ebad647a638058ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76fd05fbe15e4d83b0410e2e081b5824",
              "IPY_MODEL_6d0d1c53599b45279453ccaf390e08e5",
              "IPY_MODEL_c3c0583f9f314adcbc3d1e6c0d9e412b"
            ],
            "layout": "IPY_MODEL_68e78e9e9d174466a17f53cc66896c4a"
          }
        },
        "ea1d77a9fb504379979403c8d00fb315": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb7c4edeac6843dfb8bb2d0e6412d376": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_182b5d77998c43cda26c8bf442881780",
            "max": 1958,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ededa41d1e054083956c19e46e4866bf",
            "value": 1958
          }
        },
        "ededa41d1e054083956c19e46e4866bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f034561e6d0e4ad6a67d68cf9a3899e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4487c00ed054ad9b326449607b73b20",
              "IPY_MODEL_015ff099ca4b477b9fc4e484db77f330",
              "IPY_MODEL_ad7b87183aa54bb69669ba6d77b77f8c"
            ],
            "layout": "IPY_MODEL_383b9bdbf235450ba24127329f4c3055"
          }
        },
        "f19f6758c2854065a696e010d8a24f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2e5368962d04b66bcad044b78ee569b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3c4b933e7be4e22bbf4450dd982eeb0",
              "IPY_MODEL_4f75d233562142608e848df70a578b6d",
              "IPY_MODEL_8f9a66713b344c27b6af1d017966bce1"
            ],
            "layout": "IPY_MODEL_667e57c917654d0995c1814d3ef9859b"
          }
        },
        "f82260623c3b452fbd4f25b4eea122c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f922a9a5d2de4a918e06cfd7e6f463e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f958abd6a3244a1ea0648d49406bc229": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
